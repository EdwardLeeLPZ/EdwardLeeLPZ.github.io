<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://edwardleelpz.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://edwardleelpz.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-12-25T04:38:36+00:00</updated><id>https://edwardleelpz.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">SpaceDrive：Infusing Spatial Awareness into VLM-based Autonomous Driving</title><link href="https://edwardleelpz.github.io/english/2025/12/24/spacedrive.html" rel="alternate" type="text/html" title="SpaceDrive：Infusing Spatial Awareness into VLM-based Autonomous Driving"/><published>2025-12-24T00:00:00+00:00</published><updated>2025-12-24T00:00:00+00:00</updated><id>https://edwardleelpz.github.io/english/2025/12/24/spacedrive</id><content type="html" xml:base="https://edwardleelpz.github.io/english/2025/12/24/spacedrive.html"><![CDATA[<div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog_images/spacedrive/spacedrive_teaser-480.webp 480w,/assets/img/blog_images/spacedrive/spacedrive_teaser-800.webp 800w,/assets/img/blog_images/spacedrive/spacedrive_teaser-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blog_images/spacedrive/spacedrive_teaser.png" class="img-fluid rounded" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p><strong>Paper Title:</strong> SpaceDrive: Infusing Spatial Awareness into VLM-based Autonomous Driving</p> <p><strong>Paper Link:</strong> <a href="https://arxiv.org/abs/2512.10719">https://arxiv.org/abs/2512.10719</a></p> <p><strong>Project Page:</strong> <a href="https://zhenghao2519.github.io/SpaceDrive_Page/">https://zhenghao2519.github.io/SpaceDrive_Page/</a></p> <p><strong>Authors:</strong> <a href="https://edwardleelpz.github.io/"><em>Peizheng Li</em></a>, <a href="https://zhenghao2519.github.io/"><em>Zhenghao Zhang</em></a>, <a href="https://scholar.google.com/citations?user=gf09DbwAAAAJ&amp;hl=en&amp;oi=sra"><em>David Holtz</em></a>, <a href="https://scholar.google.com/citations?user=yEY9n1EAAAAJ&amp;hl=en"><em>Hang Yu</em></a>, <a href="https://scholar.google.com/citations?user=kg9OvU0AAAAJ&amp;hl=en"><em>Yutong Yang</em></a>, <a href="https://scholar.google.com/citations?user=9Z6Gjo4AAAAJ&amp;hl=en"><em>Yuzhi Lai</em></a>, <a href="https://rruisong.github.io/"><em>Rui Song</em></a>, <a href="https://www.cvlibs.net/"><em>Andreas Geiger</em></a>, <a href="https://uni-tuebingen.de/en/fakultaeten/mathematisch-naturwissenschaftliche-fakultaet/fachbereiche/informatik/lehrstuehle/kognitive-systeme/the-chair/staff/prof-dr-andreas-zell/"><em>Andreas Zell</em></a></p> <p><strong>Affiliations:</strong> Mercedes-Benz AG, University of Tübingen, Tübingen AI Center, TU Munich, Karlsruhe Institute of Technology, University of Stuttgart, UCLA</p> <h2 id="abstract"><strong>Abstract</strong></h2> <p>Vision-Language-Action Models (VLAs) are emerging as a new paradigm for end-to-end autonomous driving, leveraging their strong generalization and semantic understanding capabilities. However, existing 2D VLM-based driving systems exhibit significant shortcomings in handling fine-grained 3D spatial relationships, which are core requirements for spatial reasoning and trajectory planning. To address this, Mercedes-Benz and the University of Tübingen jointly propose <strong>SpaceDrive</strong>, a spatially-aware VLM-based autonomous driving framework. Its core innovation lies in abandoning the conventional VLM approach of treating coordinate values as text tokens, and instead introducing <strong>3D Positional Encoding (PE) as a universal spatial representation</strong>. Specifically, SpaceDrive first explicitly fuses visual tokens with 3D PE in the feature space. It then uses the same universal 3D PE to replace the corresponding coordinate text tokens in the prompt, serving as the interface for the foundation model’s input and output. Furthermore, SpaceDrive employs a regression decoder instead of a classification head to predict planned trajectory coordinates, circumventing the inherent limitations of language models in numerical processing. Experiments show that compared to existing VLM/VLA methods, SpaceDrive achieves state-of-the-art (SOTA) performance in open-loop evaluation on nuScenes and ranks second in the closed-loop Bench2Drive evaluation with a driving score of 78.02, significantly improving planning geometric accuracy and safety.</p> <h2 id="core-insights"><strong>Core Insights</strong></h2> <p>Current VLM applications in autonomous driving face two fundamental limitations that constrain their potential as general driving agents:</p> <ul> <li><strong>Disconnect between 2D Semantics and 3D Geometry:</strong> VLMs are primarily pre-trained on large-scale 2D image-text pairs, leading to a severe lack of 3D spatial priors. This results in ambiguous scene descriptions and defective spatial reasoning capabilities.</li> <li><strong>Defects of Numerical Tokenization:</strong> In language models, coordinates are typically decomposed digit-by-digit into characters or numbers (e.g., “3.82” becomes “3”, “.”, “8”, “2”). This process essentially fits the joint distribution of tokens rather than performing numerical computation. It ignores the continuous, neighboring structure of numerical values (e.g., “3.72” is closer to “3.82” than “3.12”) and averages the importance of tokens from different digit positions (e.g., equal loss weight for “3” and “2” in “3.82”), fundamentally limiting the accuracy and stability of continuous numerical prediction.</li> </ul> <p>Existing VLM-based planners often overlook these issues or resort to training specific embeddings/queries for particular tasks to predict coordinates, making them difficult to transfer to upstream reasoning or other tasks.</p> <p>However, <strong>the Positional Encoding (PE) within the Transformer architecture inherently handles positional relationships between tokens</strong>, which can be viewed as <strong>spatial relationships between semantic features</strong>. Inspired by this, SpaceDrive replaces textual numerical tokens with an <strong>explicit, unified 3D Positional Encoding</strong>. This converts coordinate descriptions into a unified representation that is computable, alignable, and directly usable by attention mechanisms, thereby enhancing the system’s spatial reasoning and trajectory planning capabilities.</p> <h2 id="method"><strong>Method</strong></h2> <p>The core of the SpaceDrive framework is its unified spatial interface:</p> <ul> <li><strong>Visual Side:</strong> A frozen depth estimator obtains absolute depth for each image patch, which is projected to 3D coordinates. These coordinates are then encoded by a PE module and added to the corresponding visual tokens, yielding spatial-aware visual tokens.</li> <li><strong>Text Side:</strong> After tokenization, the text is scanned for coordinate expressions. Their numerical values are parsed and encoded by the same PE encoder to produce spatial tokens, which replace the original sequence of number tokens. A special prefix indicator ⟨IND⟩ marks these tokens.</li> <li><strong>Output Side:</strong> The language head generates text normally. When ⟨IND⟩ is generated, the subsequent hidden state is fed into a PE decoder to directly regress 3D/BEV coordinates, replacing the digit-by-digit generation of numbers.</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog_images/spacedrive/spacedrive_architecture-480.webp 480w,/assets/img/blog_images/spacedrive/spacedrive_architecture-800.webp 800w,/assets/img/blog_images/spacedrive/spacedrive_architecture-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blog_images/spacedrive/spacedrive_architecture.png" class="img-fluid rounded" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">SpaceDrive Architecture</figcaption> </figure> </div> </div> <h3 id="perception-phase-explicit-fusion-of-vision-and-depth">Perception Phase: Explicit Fusion of Vision and Depth</h3> <p>While using a VLM’s pre-trained visual encoder to extract visual tokens, SpaceDrive employs a frozen depth estimator (e.g., UniDepthV2) to obtain absolute depth. Combining this with camera intrinsics and extrinsics, the center of each image patch is projected into metric 3D space \(\mathbf{c}_p = (x_p^{3D}, y_p^{3D}, z_p^{3D})\). These 3D coordinates are mapped to a PE vector \(\phi(\mathbf{c}_p)\) of the same dimension as the tokens by a universal PE encoder. To avoid confusion with the base VLM’s RoPE, SpaceDrive adopts Sine-cosine encoding as the PE encoder:</p> \[\phi(\mathbf{c}_p)=\big[\phi_x(x_p^{3D}),\phi_y(y_p^{3D}),\phi_z(z_p^{3D})\big]\in\mathbb{R}^{dim}, \text{with} \\\] \[\phi_a(p_a) =\begin{cases} \sin(\tfrac{p_a}{20000^{2i/d_a}}),\\ \cos(\tfrac{p_a}{20000^{2i/d_a}}), \end{cases} i=0,\dots,\lfloor\tfrac{d_a}{2}\rfloor-1,\\\] \[d_x=d_y=\lceil\tfrac{dim}{3}\rceil, d_z={dim}-d_x-d_y.\] <p>The channels of the above 3D PE are allocated along the \(x/y/z\) dimensions. This 3D PE is then directly added to the modality-aligned visual token \(h_p\), thereby infusing the VLM’s visual input with absolute spatial coordinate information:</p> \[\tilde{h}_p = h_p + \alpha_{PE}\, \phi(\mathbf{c}_p).\] <p>Considering that sparse queries (like in Q-Former) are difficult to densely align with specific 3D locations and require additional alignment pre-training, visual tokens in SpaceDrive are aligned with the language space via an MLP projector. The \(\alpha_{PE}\) in the formula is a learnable normalization factor to avoid training instability caused by deviation of the token norm distribution from the pre-training distribution.</p> <p><strong>Spatial Information Retrieval:</strong> Since attention is based on dot-product similarity retrieval, adding 3D PE to visual tokens essentially makes spatial location a <strong>key-value structure directly retrievable by attention</strong>. Consequently, coordinate PEs in subsequent text can use similarity to index semantic features at corresponding spatial locations, rather than relying on the language model to guess.</p> <h3 id="reasoning-phase-unified-coordinate-interface">Reasoning Phase: Unified Coordinate Interface</h3> <p>When 3D coordinates appear in the input prompt, for a coordinate substring \(S_r\) in the text prompt, its numerical value \(\mathbf{c}_r = (x_r,y_r,z_r)\) is extracted and encoded using the same unified PE encoder \(\phi(\cdot)\). These encoded 3D PEs replace the original sequence of number tokens and are preceded by the special token ⟨IND⟩ to avoid semantic confusion (for special cases like BEV coordinates, e.g., trajectory waypoints, the \(z\)-axis component in the PE is set to 0 to avoid affecting attention calculation).</p> \[\tilde{h}_i=\begin{cases}\phi(\mathbf{c}_r) &amp; i\in\mathcal{S}_r \\ \mathrm{Tokenizer}(t_i) &amp; \text{otherwise}\end{cases} .\] <p>In addition to basic prompt input, the vehicle’s Ego Status has proven highly effective for trajectory planning. Existing methods typically encode all state variables (e.g., pose, velocity, acceleration) into a single vector embedding \(\mathbf{e}_{\text{ego}}\in\mathbb{R}^{dim}\). Benefiting from the unified spatial representation, SpaceDrive can also encode historical Ego waypoints using the same \(\phi(\cdot)\) and input them along with \(\mathbf{e}_{\text{ego}}\) as explicit spatiotemporal conditions to the language model for precise trajectory planning.</p> <p><strong>Logical Consistency:</strong> By using the same set of PE for vision, text prompts, and Ego waypoints, the model is compelled to learn a unified spatial semantic indexing, rather than learning disjointed mappings for different modalities.</p> <h3 id="output-phase-regression-over-classification">Output Phase: Regression Over Classification</h3> <p>During output generation, when the model’s language head predicts the special indicator token ⟨IND⟩ from \(\mathbf{e}_j\), the next step’s embedding output \(\mathbf{e}_{j+1}\) will be decoded into 3D coordinates by a dedicated PE decoder \(\psi(\cdot)\):</p> \[\hat{\mathbf{c}} = \psi(\mathbf{e}_{j+1}), \, \hat{\mathbf{c}} \in \mathbb{R}^3.\] <p>Considering that Sine-cosine PE is not analytically invertible (phase/frequency aliasing), the PE decoder is made learnable. This decoder can employ an MLP for deterministic coordinate regression output or choose a generative module like a VAE for multi-modal output. SpaceDrive defaults to using a lightweight MLP as the PE decoder.</p> <h3 id="loss-function"><strong>Loss Function</strong></h3> <p>For coordinate prediction, SpaceDrive employs Huber Loss for supervision, which balances outliers and convergence accuracy better than L2 or L1 loss. The text part retains the original cross-entropy loss:</p> \[\mathcal{L} = \mathcal{L}_{\text{LM}} + \mathcal{L}_{\text{Huber}}(\hat{\mathbf{c}}, \mathbf{c}).\] <h2 id="experiments-and-visualization"><strong>Experiments and Visualization</strong></h2> <p>The paper validates SpaceDrive and SpaceDrive+ (with Ego Status input) for open-loop and closed-loop planning on the nuScenes dataset and the Bench2Drive benchmark, respectively. In experiments, the framework is based on the Qwen2.5-VL-7B VLM, fine-tuned using LoRA alignment with a rank of 16. A frozen pre-trained Unidepthv2-ViT-L serves as the depth estimation module. For open-loop planning, the model predicts 6 points over a 3-second future horizon. Closed-loop planning follows SimLingo, outputting both path and speed waypoints for vehicle PID control.</p> <h3 id="open-loop-planning-nuscenes"><strong>Open-loop Planning (nuScenes)</strong></h3> <p>To directly verify trajectory planning accuracy, an open-loop evaluation was first conducted. On the nuScenes dataset, SpaceDrive+ outperforms existing VLM-based methods like OmniDrive/ORION across all metrics (Avg. L2 = 0.32m, Avg. Collision = 0.23%, Avg. Intersection = 1.27%).</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog_images/spacedrive/openloop_eval-480.webp 480w,/assets/img/blog_images/spacedrive/openloop_eval-800.webp 800w,/assets/img/blog_images/spacedrive/openloop_eval-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blog_images/spacedrive/openloop_eval.png" class="img-fluid rounded" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">开环规划性能对比</figcaption> </figure> </div> </div> <p>Notably: The SpaceDrive framework <strong>does not rely on BEV features at all</strong>. The results still demonstrate that the unified positional encoding interface is sufficient to support 3D spatial modeling within the VLM, architecturally reducing dependency on dense BEV representations.</p> <h3 id="closed-loop-planning-bench2drive"><strong>Closed-loop Planning (Bench2Drive)</strong></h3> <p>Considering that similarity-based open-loop planning evaluation is highly susceptible to dataset overfitting and cannot fully reflect a model’s actual driving capability, the paper further validates the method’s effectiveness in the closed-loop Bench2Drive benchmark.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog_images/spacedrive/closeloop_eval-480.webp 480w,/assets/img/blog_images/spacedrive/closeloop_eval-800.webp 800w,/assets/img/blog_images/spacedrive/closeloop_eval-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blog_images/spacedrive/closeloop_eval.png" class="img-fluid rounded" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">闭环规划性能对比</figcaption> </figure> </div> </div> <p>The paper first attempted a method using only text generation for trajectories. Experiments proved this method tends to degenerate into near-linear trajectories with oscillating headings in closed-loop, being highly unstable. This is because text generation essentially fits data priors rather than learning a controllable policy. In contrast, after introducing explicit universal spatial tokens, SpaceDrive+ achieves a Driving Score of 78.02 and a Success Rate of 55.11%, ranking second among VLM-based methods.</p> <h3 id="visualization"><strong>Visualization</strong></h3> <p>The paper compares the performance of the pure text method and the method incorporating spatial tokens in the same scenario (lane change to avoid a cyclist):</p> <ul> <li>The pure text method’s output trajectory degenerates into a straight line with constantly oscillating direction, eventually causing the vehicle to swerve left significantly until colliding with a guardrail.</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog_images/spacedrive/closeloop_vis_omnidrive-480.webp 480w,/assets/img/blog_images/spacedrive/closeloop_vis_omnidrive-800.webp 800w,/assets/img/blog_images/spacedrive/closeloop_vis_omnidrive-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blog_images/spacedrive/closeloop_vis_omnidrive.png" class="img-fluid rounded" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">Pure text method degenerates in closed-loop simulation</figcaption> </figure> </div> </div> <ul> <li>SpaceDrive+ with spatial tokens, upon observing a slow cyclist ahead, first tentatively accelerates to seek an overtaking opportunity. Finding the adjacent vehicle does not yield, it decelerates to create a safe insertion gap, then decisively changes lanes, and corrects the steering in time before completing the lane change to avoid leaving the road.</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog_images/spacedrive/closeloop_vis_spacedrive-480.webp 480w,/assets/img/blog_images/spacedrive/closeloop_vis_spacedrive-800.webp 800w,/assets/img/blog_images/spacedrive/closeloop_vis_spacedrive-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blog_images/spacedrive/closeloop_vis_spacedrive.png" class="img-fluid rounded" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">SpaceDrive can handle complex closed-loop driving scenarios</figcaption> </figure> </div> </div> <h2 id="ablation-studies"><strong>Ablation Studies</strong></h2> <p>To further validate how the universal 3D PE contributes to planning, numerous ablation studies were conducted, leading to the following conclusions:</p> <ul> <li><strong>PE Injection Location is Crucial:</strong> Using PE only for text coordinate replacement without injecting it into visual tokens offers limited improvement (as PE cannot index corresponding visual features). Injecting 3D PE into visual tokens brings significant gains. When unified positional encoding is applied to both visual and text coordinate streams, planning performance improves regardless of ego state usage, highlighting the value of a shared spatial representation.</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog_images/spacedrive/abl_pe-480.webp 480w,/assets/img/blog_images/spacedrive/abl_pe-800.webp 800w,/assets/img/blog_images/spacedrive/abl_pe-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blog_images/spacedrive/abl_pe.png" class="img-fluid rounded" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">Ablation Study on PE Injection Location</figcaption> </figure> </div> </div> <ul> <li><strong>Choice of PE Encoder/Decoder is Important:</strong> Sine-cosine encoding inherently offers better translation equivariance, aiding the attention mechanism in understanding spatial relationships between tokens, outperforming a learnable MLP encoder. RoPE conflicts with the base VLM’s RoPE, causing semantic instability in outputs. Directly inverting sine-cosine at the output is ill-posed, and the VLM’s output space is not fully aligned with its input embedding space. Therefore, a learnable, per-waypoint MLP decoder is superior.</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog_images/spacedrive/abl_pe_en_de-480.webp 480w,/assets/img/blog_images/spacedrive/abl_pe_en_de-800.webp 800w,/assets/img/blog_images/spacedrive/abl_pe_en_de-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blog_images/spacedrive/abl_pe_en_de.png" class="img-fluid rounded" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">Ablation Study on PE Encoder and Decoder</figcaption> </figure> </div> </div> <ul> <li><strong>Learnable \(α_{PE}\) is Important:</strong> Fixed-scale PE easily causes semantic instability or convergence difficulties, while a learnable α_{PE} significantly improves L2 error, collision rate, and out-of-bounds rate.</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog_images/spacedrive/abl_pe_norm-480.webp 480w,/assets/img/blog_images/spacedrive/abl_pe_norm-800.webp 800w,/assets/img/blog_images/spacedrive/abl_pe_norm-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blog_images/spacedrive/abl_pe_norm.png" class="img-fluid rounded" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">Ablation Study on PE Norm</figcaption> </figure> </div> </div> <ul> <li><strong>PE Representation as an Interface is Transferable:</strong> The same set of PE spatial interface yields similar performance gains on both Qwen-VL and LLaVA, indicating that the benefits stem primarily from the unified spatial reasoning interface rather than specific adaptation to a particular base model.</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog_images/spacedrive/abl_vlm-480.webp 480w,/assets/img/blog_images/spacedrive/abl_vlm-800.webp 800w,/assets/img/blog_images/spacedrive/abl_vlm-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blog_images/spacedrive/abl_vlm.png" class="img-fluid rounded" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">Ablation Study on Different VLM Base Models</figcaption> </figure> </div> </div> <p>Additionally, supplementary materials present more experiments related to VQA tasks, different depth estimation models, and various hyperparameters, further confirming the effectiveness of the proposed method.</p> <h2 id="conclusion"><strong>Conclusion</strong></h2> <p>SpaceDrive makes several key contributions to current autonomous driving and VLM research:</p> <ul> <li><strong>Universal Spatial Representation:</strong> It introduces a unified 3D Positional Encoding that works consistently across perception, reasoning, and planning modules, representing a significant architectural innovation. This approach moves beyond task-specific embeddings towards more general spatial intelligence.</li> <li><strong>Explicit 3D Understanding:</strong> Additively integrating spatial encoding with visual tokens creates an explicit link between semantic content and 3D location, enabling more accurate scene understanding and reasoning.</li> <li><strong>Regression Respects Numerical Nature:</strong> By replacing digit-by-digit coordinate generation with regression-based dedicated decoding, SpaceDrive addresses a fundamental limitation of language models in handling continuous numerical quantities.</li> <li><strong>Framework Generality:</strong> The method demonstrates compatibility with different VLM architectures (Qwen-VL, LLaVA) and proves suitable for inference-time enhancements like chain-of-thought reasoning, indicating broad applicability.</li> </ul> <p>In summary, SpaceDrive provides a rigorous paradigm shift: <strong>from “modeling geometry with language” to “explicitly encoding geometry.”</strong> Its core contribution lies in demonstrating that within VLMs, a <strong>unified, modality/task-agnostic 3D positional encoding</strong> can effectively connect the perceived visual space with the planned physical space. This approach not only addresses the hallucination and accuracy issues of VLMs in large-scale spatial reasoning tasks but also preserves their general advantage in long-tail scene understanding. SpaceDrive represents a significant step towards enabling VLMs to interact effectively with the physical world through precise spatial understanding, pointing the way forward for more reliable and capable AI agents.</p>]]></content><author><name></name></author><category term="English"/><category term="Paper"/><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">SpaceDrive：为自动驾驶VLA注入空间智能</title><link href="https://edwardleelpz.github.io/%E4%B8%AD%E6%96%87/2025/12/24/spacedrive.html" rel="alternate" type="text/html" title="SpaceDrive：为自动驾驶VLA注入空间智能"/><published>2025-12-24T00:00:00+00:00</published><updated>2025-12-24T00:00:00+00:00</updated><id>https://edwardleelpz.github.io/%E4%B8%AD%E6%96%87/2025/12/24/spacedrive</id><content type="html" xml:base="https://edwardleelpz.github.io/%E4%B8%AD%E6%96%87/2025/12/24/spacedrive.html"><![CDATA[<div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog_images/spacedrive/spacedrive_teaser-480.webp 480w,/assets/img/blog_images/spacedrive/spacedrive_teaser-800.webp 800w,/assets/img/blog_images/spacedrive/spacedrive_teaser-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blog_images/spacedrive/spacedrive_teaser.png" class="img-fluid rounded" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p><strong>论文标题：</strong> SpaceDrive: Infusing Spatial Awareness into VLM-based Autonomous Driving</p> <p><strong>论文链接：</strong> <a href="https://arxiv.org/abs/2512.10719">https://arxiv.org/abs/2512.10719</a></p> <p><strong>项目主页：</strong> <a href="https://zhenghao2519.github.io/SpaceDrive_Page/">https://zhenghao2519.github.io/SpaceDrive_Page/</a></p> <p><strong>作者名单：</strong> <a href="https://edwardleelpz.github.io/"><em>Peizheng Li</em></a>, <a href="https://zhenghao2519.github.io/"><em>Zhenghao Zhang</em></a>, <a href="https://scholar.google.com/citations?user=gf09DbwAAAAJ&amp;hl=en&amp;oi=sra"><em>David Holtz</em></a>, <a href="https://scholar.google.com/citations?user=yEY9n1EAAAAJ&amp;hl=en"><em>Hang Yu</em></a>, <a href="https://scholar.google.com/citations?user=kg9OvU0AAAAJ&amp;hl=en"><em>Yutong Yang</em></a>, <a href="https://scholar.google.com/citations?user=9Z6Gjo4AAAAJ&amp;hl=en"><em>Yuzhi Lai</em></a>, <a href="https://rruisong.github.io/"><em>Rui Song</em></a>, <a href="https://www.cvlibs.net/"><em>Andreas Geiger</em></a>, <a href="https://uni-tuebingen.de/en/fakultaeten/mathematisch-naturwissenschaftliche-fakultaet/fachbereiche/informatik/lehrstuehle/kognitive-systeme/the-chair/staff/prof-dr-andreas-zell/"><em>Andreas Zell</em></a></p> <p><strong>作者机构：</strong> Mercedes-Benz AG，University of Tübingen，Tübingen AI Center，TU Munich，Karlsruhe Institute of Technology，University of Stuttgart，UCLA</p> <h2 id="摘要"><strong>摘要</strong></h2> <p>VLA凭借其强大的泛化能力和语义理解能力逐渐成为端到端自动驾驶新范式。然而，现有的基于2D VLM的驾驶系统在处理精细的3D空间关系时存在显著缺陷，而这却是空间推理和轨迹规划的核心要求。为此，奔驰与图宾根大学联合提出了一种名为<strong>SpaceDrive</strong>的具备空间意识的VLM自动驾驶框架。其核心在于摒弃了传统VLM将坐标数值视为文本token的处理方式，转而引入<strong>3D位置编码（Positional Encoding, PE）作为通用的空间表征</strong>。具体来说，SpaceDrive首先将视觉token与3D PE在特征空间进行显式融合，同时沿用上述通用的3D PE来取代prompt中对应坐标的文本token作为foundation model输入输出的接口。此外，SpaceDrive还采用回归解码器替代分类头预测规划的轨迹坐标，避免了语言模型在数字处理上的天然缺陷。实验表明，与现有VLM/VLA类方法相比，SpaceDrive在nuScenes开环评估中取得了SOTA性能，并在Bench2Drive闭环评估中以78.02的驾驶得分位列第二，显著提升了规划的几何精度与安全性。</p> <h2 id="核心要点"><strong>核心要点</strong></h2> <p>当前VLM在自动驾驶应用中面临两个根本性的系统缺陷，这限制了其作为通用驾驶Agent的上限：</p> <ul> <li><strong>2D语义与3D几何的割裂</strong>：VLM主要在大规模2D图像-文本对上进行预训练，极度缺乏3D空间先验，导致场景描述模糊和空间推理能力存在缺陷。</li> <li><strong>数字 token 化的缺陷</strong>：语言模型中坐标通常被逐位拆解为字符或数字（例如将坐标”3.82”拆解为”3”, “.”, “8”, “2”），其本质是token联合分布的拟合而非数值计算。它既忽略了数值的连续邻近结构（例如”3.72”比”3.12”接近”3.82”），也会把不同位的 token 重要性平均化（例如”3.82”中”3”和”2”的Loss权重相同），从机制上拉低了连续数值预测精度与稳定性。</li> </ul> <p>而现有VLM-based planner常常忽略了上述问题，或直接采用特定的 embedding/queries 针对某个任务进行训练来预测坐标，难以被迁移到上游推理或者其他任务中。</p> <p>但是，<strong>Transformer架构本身的位置编码已经具备了处理token间位置关系的能力</strong>，这可以被视为<strong>语义特征之间的空间关系</strong>。受此启发，SpaceDrive通过<strong>显式的、统一的3D位置编码</strong>替换文本数字token，将坐标的语言描述转换成可计算、可对齐、可被注意力直接使用的统一表示，从而提升了系统的空间推理和轨迹规划能力。</p> <h2 id="方法"><strong>方法</strong></h2> <p>SpaceDrive框架的核心在于统一的空间接口：</p> <ul> <li><strong>视觉侧</strong>：用冻结深度估计器得到每个 patch 的绝对深度，投影为 3D 坐标，再经 PE 编码后加到对应视觉 token 上，得到 spatial-aware visual tokens。</li> <li><strong>文本侧</strong>：在 tokenizer 后扫描文本中的坐标表达，将其数值解析出来，经同一个 PE 编码器得到空间 token，替换原来的数字 token 序列，并用特殊前缀指示符 ⟨IND⟩ 标记。</li> <li><strong>输出侧</strong>：语言头正常生成文本；当生成 ⟨IND⟩ 时，后续 hidden state 送入 PE decoder直接回归 3D/BEV 坐标，取代生成数字的逐位生成。</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog_images/spacedrive/spacedrive_architecture-480.webp 480w,/assets/img/blog_images/spacedrive/spacedrive_architecture-800.webp 800w,/assets/img/blog_images/spacedrive/spacedrive_architecture-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blog_images/spacedrive/spacedrive_architecture.png" class="img-fluid rounded" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">SpaceDrive框架图</figcaption> </figure> </div> </div> <h3 id="感知阶段视觉与深度的显式融合">感知阶段：视觉与深度的显式融合</h3> <p>SpaceDrive在采用VLM预训练的视觉编码器提取视觉token的同时，利用冻结的深度估计器（如UniDepthV2）获取绝对深度，结合相机内外参将图像Patch中心投影至3D度量空间 \(\mathbf{c}_p = (x_p^{3D}, y_p^{3D}, z_p^{3D})\) 。这些3D坐标会被一个通用的PE编码器被映射为与token维度相同的PE向量 \(\phi(\mathbf{c}_p)\) 。为了避免和原始VLM中的RoPE混淆，SpaceDrive采用了正余弦（Sine-cosine）编码作为PE编码器：</p> \[\phi(\mathbf{c}_p)=\big[\phi_x(x_p^{3D}),\phi_y(y_p^{3D}),\phi_z(z_p^{3D})\big]\in\mathbb{R}^{dim}, \text{with} \\\] \[\phi_a(p_a) =\begin{cases} \sin(\tfrac{p_a}{20000^{2i/d_a}}),\\ \cos(\tfrac{p_a}{20000^{2i/d_a}}), \end{cases} i=0,\dots,\lfloor\tfrac{d_a}{2}\rfloor-1,\\\] \[d_x=d_y=\lceil\tfrac{dim}{3}\rceil, d_z={dim}-d_x-d_y.\] <p>上述3D PE按 \(x/y/z\) 维分配通道。该3D PE随后被直接叠加到经过模态对齐的视觉Token \(h_p\) 上，从而为VLM的视觉输入注入了绝对空间坐标信息：</p> \[\tilde{h}_p = h_p + \alpha_{PE}\, \phi(\mathbf{c}_p).\] <p>考虑到Q-Former一类稀疏queries难以与具体 3D 位置密集对齐且需要额外对齐预训练，在SpaceDrive中视觉token通过MLP projector 与语言空间对齐。公式中的 \(α_{PE}\) 是一个可学习的归一化因子，以避免 token norm 分布偏离预训练分布造成的训练不稳定。</p> <p><strong>空间信息检索</strong>：由于注意力是基于点积相似度的检索， 3D PE与视觉 token的叠加，相当于把空间位置变成<strong>可被注意力直接检索的键值结构</strong>。因此，后续文本中的坐标 PE 就能用相似度去索引对应空间位置上的语义特征，而非通过语言模型进行猜测。</p> <h3 id="推理阶段统一坐标接口">推理阶段：统一坐标接口</h3> <p>当 3D 坐标出现在输入提示中时，对文本Prompt中的坐标子串 \(S_r\) ，其数值 \(\mathbf{c}_r = (x_r,y_r,z_r)\) 被提取并使用与上述相同的统一 PE 编码器 \(\phi(·)\) 进行编码。这些编码后的3D PE会替换原本的数字 token 序列，并在前面插入特殊 token ⟨IND⟩ 避免语义混淆（对于 BEV 坐标这种特殊情况，例如轨迹航点，PE中的 \(z\) 轴分量会被置0，避免影响注意力计算）。</p> \[\tilde{h}_i=\begin{cases}\phi(\mathbf{c}_r) &amp; i\in\mathcal{S}_r \\ \mathrm{Tokenizer}(t_i) &amp; \text{otherwise}\end{cases} .\] <p>除了基本的prompt输入外，车辆的Ego Status也被证明对于轨迹规划非常有效。现有方法通常将所有状态变量（例如姿态、速度、加速度）简单地编码成一个单一的向量嵌入 \(\mathbf{e}_{\text{ego}}\in\mathbb{R}^{dim}\) 。得益于统一空间表示，SpaceDrive同样可以通过之前使用的相同 \(\phi(\cdot)\) 编码历史Ego waypoints，并将其与 \(\mathbf{e}_{\text{ego}}\) 一起作为显式的时空条件输入到语言模型中，以实现精确的轨迹规划。</p> <p><strong>逻辑一致性</strong>：通过在视觉、文本Prompt、Ego waypoints中使用同一套PE，模型被要求学习统一的空间语义索引，而非针对不同模态学习割裂的映射。</p> <h3 id="输出阶段回归优于分类">输出阶段：回归优于分类</h3> <p>在输出生成时，当模型语言头预测 \(\mathbf{e}_j\) 得到特殊指示符token ⟨IND⟩ 时，下一步的嵌入输出 \(\mathbf{e}_{j+1}\) 将会被一个专用的 PE 解码器 \(\psi(\cdot)\) 解码为 3D 坐标：</p> \[\hat{\mathbf{c}} = \psi(\mathbf{e}_{j+1}), \, \hat{\mathbf{c}} \in \mathbb{R}^3.\] <p>考虑到 Sine-cosine PE 不可解析逆（相位/频率混叠），因此PE解码器被设为可学习的。该解码器既可以采用MLP以获得确定的坐标回归输出，也可以选择VAE等生成式模块从而获得多模式的输出。SpaceDrive默认采用一个轻量化的MLP作为PE解码器。</p> <h3 id="损失函数"><strong>损失函数</strong></h3> <p>对于坐标预测，SpaceDrive采用Huber Loss进行监督，相比L2或L1更能平衡异常值与收敛精度；文本部分SpaceDrive则保留了原有的交叉熵损失 ：</p> \[\mathcal{L} = \mathcal{L}_{\text{LM}} + \mathcal{L}_{\text{Huber}}(\hat{\mathbf{c}}, \mathbf{c}).\] <h2 id="实验及可视化"><strong>实验及可视化</strong></h2> <p>论文分别在nuScenes数据集和Bench2Drive 基准测试上对SpaceDrive以及带有Ego Status输入的SpaceDrive+进行了开环和闭环规划验证。实验中，框架以Qwen2.5-VL-7B为基础VLM，使用rank为16的LoRA对齐进行微调。冻结的预训练Unidepthv2-ViT-L被用作深度估计模块。开环规划中，模型预测未来3秒内的6个点作为输出，而闭环规划则是参照了SimLingo，同时输出path和speed waypoints，用于车辆PID控制。</p> <h3 id="开环规划-nuscenes"><strong>开环规划 (nuScenes)</strong></h3> <p>为了直接验证轨迹规划的准确性，论文首先进行了一次开环评估。在nuScenes数据集上，SpaceDrive+ 在所有指标上均超越了现有的OmniDrive/ORION 等 VLM-based 方法（Avg. L2 = 0.32m、Avg. Collision = 0.23%、Avg. Intersection = 1.27%）。</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog_images/spacedrive/openloop_eval-480.webp 480w,/assets/img/blog_images/spacedrive/openloop_eval-800.webp 800w,/assets/img/blog_images/spacedrive/openloop_eval-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blog_images/spacedrive/openloop_eval.png" class="img-fluid rounded" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">开环规划性能对比</figcaption> </figure> </div> </div> <p>值得注意的是：SpaceDrive框架<strong>完全不依赖 BEV 特征</strong>。结果仍表明，统一位置编码接口足以支撑 VLM 内部的 3D 空间建模，从架构上减少对密集 BEV 表征的依赖。</p> <h3 id="闭环规划-bench2drive"><strong>闭环规划 (Bench2Drive)</strong></h3> <p>考虑到基于相似度的开环规划评估极易受到数据集过拟合的影响，难以全面反映模型实际驾驶能力。论文进一步在闭环Bench2Drive基准测试中进一步验证了其方法的有效性。</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog_images/spacedrive/closeloop_eval-480.webp 480w,/assets/img/blog_images/spacedrive/closeloop_eval-800.webp 800w,/assets/img/blog_images/spacedrive/closeloop_eval-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blog_images/spacedrive/closeloop_eval.png" class="img-fluid rounded w-50" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">闭环规划性能对比</figcaption> </figure> </div> </div> <p>论文首先尝试了仅使用文本生成轨迹的方法，实验证明该方法在闭环里容易退化为近线性轨迹，且航向出现振荡，极不稳定。这是由于文本生成本质是在拟合数据先验而非学习可控策略。相比之下引入显式的通用空间 token 后，SpaceDrive+ 达到 78.02 Driving Score 与 55.11% Success Rate，在 VLM-based 方法中排名第二。</p> <h3 id="可视化"><strong>可视化</strong></h3> <p>论文对比了同一场景下（变道避让骑行者）纯文本和引入空间token方法的实际表现：</p> <ul> <li>纯文本方法输出的轨迹规划退化为一条直线，且行进方向不断震荡，最终导致车辆向左大幅偏转直至撞上护栏；</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog_images/spacedrive/closeloop_vis_omnidrive-480.webp 480w,/assets/img/blog_images/spacedrive/closeloop_vis_omnidrive-800.webp 800w,/assets/img/blog_images/spacedrive/closeloop_vis_omnidrive-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blog_images/spacedrive/closeloop_vis_omnidrive.png" class="img-fluid rounded" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">纯文本方法在闭环仿真中退化失效</figcaption> </figure> </div> </div> <ul> <li>引入空间token的SpaceDrive+在观测到前方由缓慢的骑行者时，先试探加速寻找超车机会，发现邻车并未让行后减速创造安全插入间隙，再果断变道，并在变道完成前及时回正避免驶出道路。</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog_images/spacedrive/closeloop_vis_spacedrive-480.webp 480w,/assets/img/blog_images/spacedrive/closeloop_vis_spacedrive-800.webp 800w,/assets/img/blog_images/spacedrive/closeloop_vis_spacedrive-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blog_images/spacedrive/closeloop_vis_spacedrive.png" class="img-fluid rounded" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">SpaceDrive可以胜任复杂的闭环驾驶场景</figcaption> </figure> </div> </div> <h2 id="消融实验"><strong>消融实验</strong></h2> <p>为了进一步验证通用的3D PE如何在规划中发挥作用，论文进行了诸多消融实验并得出了以下结论：</p> <ul> <li><strong>PE注入位置很关键</strong>：仅把 PE 用在文本坐标替换而不注入视觉 token提升有限（因为此时PE无法对于对应位置视觉特征进行索引）；而把 3D PE 注入视觉 token 带来显著增益；当统一的位置编码应用于视觉和文本坐标流时，无论是否使用自我状态，规划性能都会提高，这强调了共享空间表示的价值。</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog_images/spacedrive/abl_pe-480.webp 480w,/assets/img/blog_images/spacedrive/abl_pe-800.webp 800w,/assets/img/blog_images/spacedrive/abl_pe-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blog_images/spacedrive/abl_pe.png" class="img-fluid rounded" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">PE消融实验</figcaption> </figure> </div> </div> <ul> <li><strong>PE编码器/解码器选择十分重要</strong>：Sine-cosine 编码天然具备更好的平移等变性，有助于注意力机制理解 token 间空间关系，优于可学习的MLP encoder；RoPE 会与基座 VLM 的 RoPE 冲突导致输出出现语义不稳定；输出端直接反解sine-cosine 不适定，且 VLM 输出空间与输入嵌入空间不完全对齐，因此用可学习、逐坐标 waypoint 的 MLP decoder 更优。</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog_images/spacedrive/abl_pe_en_de-480.webp 480w,/assets/img/blog_images/spacedrive/abl_pe_en_de-800.webp 800w,/assets/img/blog_images/spacedrive/abl_pe_en_de-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blog_images/spacedrive/abl_pe_en_de.png" class="img-fluid rounded" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">PE编码器与解码器消融实验</figcaption> </figure> </div> </div> <ul> <li><strong>可学习的\(α_{PE}\)十分重要</strong>：固定尺度的PE容易造成语义不稳定或收敛困难，而可学习α_{PE}显著改善 L2误差、碰撞率和越界率。</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog_images/spacedrive/abl_pe_norm-480.webp 480w,/assets/img/blog_images/spacedrive/abl_pe_norm-800.webp 800w,/assets/img/blog_images/spacedrive/abl_pe_norm-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blog_images/spacedrive/abl_pe_norm.png" class="img-fluid rounded" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">PE Norm消融实验</figcaption> </figure> </div> </div> <ul> <li><strong>PE表征作为接口具备可迁移性</strong>：同一套PE空间接口在 Qwen-VL 与 LLaVA 上都能保持相近收益，说明增益主要来自统一空间推理接口而非特定基座模型的特殊适配。</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog_images/spacedrive/abl_vlm-480.webp 480w,/assets/img/blog_images/spacedrive/abl_vlm-800.webp 800w,/assets/img/blog_images/spacedrive/abl_vlm-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blog_images/spacedrive/abl_vlm.png" class="img-fluid rounded" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">不同VLM基础模型对比</figcaption> </figure> </div> </div> <p>此外，论文补充材料还展示了更多有关于VQA任务，不同深度估计模型，不同超参数的相关实验，进一步证实了所提出方法的有效性。</p> <h2 id="结论"><strong>结论</strong></h2> <p>SpaceDrive 对当下自动驾驶和 VLM 研究做出了几项重要贡献：</p> <ul> <li><strong>通用空间表示</strong>：引入统一的 3D 位置编码，在感知、推理和规划模块中始终如一地工作，代表了一项重要的架构创新。这种方法超越了特定任务的嵌入，迈向了更具通用性的空间智能。</li> <li><strong>显式3D理解</strong>：将空间编码与视觉token进行加性整合，在语义内容和 3D 位置之间创建了显式关联，从而实现了更准确的场景理解和推理。</li> <li><strong>回归坐标数值本质</strong>：通过用基于回归的专用解码取代逐位坐标生成，SpaceDrive 解决了语言模型在处理连续数值量方面的根本限制。</li> <li><strong>框架通用性</strong>：该方法展示了与不同 VLM 架构（Qwen-VL、LLaVA）的兼容性，并证明适用于推理时增强功能，如思维链推理，表明其广泛适用性。</li> </ul> <p>综上，SpaceDrive 提供了一个严谨的范式转换：<strong>从“语言建模几何”转向“显式几何编码”</strong>。其核心贡献在于证实了在VLM中，通过<strong>统一的、模态/任务无关的3D位置编码</strong>，可以有效连接感知的视觉空间与规划的物理空间。这种方法不仅解决了VLM在大规模空间推理任务中的幻觉和精度问题，还保留了VLM在长尾场景理解上的通用优势。SpaceDrive 代表了使 VLM 能够通过精确的空间理解有效与物理世界交互的重要一步，为更可靠、更有能力的 AI 智能体提供了发展方向。</p>]]></content><author><name></name></author><category term="中文"/><category term="Paper"/><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">In the Perspective of Manifold Hypotheses - 2</title><link href="https://edwardleelpz.github.io/english/2025/12/15/manifold-hypothesis-2.html" rel="alternate" type="text/html" title="In the Perspective of Manifold Hypotheses - 2"/><published>2025-12-15T00:00:00+00:00</published><updated>2025-12-15T00:00:00+00:00</updated><id>https://edwardleelpz.github.io/english/2025/12/15/manifold-hypothesis-2</id><content type="html" xml:base="https://edwardleelpz.github.io/english/2025/12/15/manifold-hypothesis-2.html"><![CDATA[<h2 id="introduction-architectural-evolution-and-the-path-traveled"><strong>Introduction: Architectural Evolution and the Path Traveled</strong></h2> <p>For a long time, we have anticipated a next-generation architecture sufficient to replace the Transformer or the existing Attention mechanism. Whether it is the Mamba series from the past two years, aiming to subvert the Transformer entirely, or the recently discussed Sparse/Gated Attention based on iterative optimization of existing mechanisms, research continues to advance, yet the goal remains elusive. Compared to the unpredictable future, perhaps the path we have traveled offers greater clarity.</p> <h2 id="i-from-mlp-to-transformer"><strong>I. From MLP to Transformer</strong></h2> <p>From the perspective of the Manifold Hypothesis, all classical architectures can be viewed as topological transformations from a curled manifold to a flat feature space, each carrying different Inductive Biases.</p> <h3 id="1-mlp-the-universal-manifold-operator-with-no-structural-priors"><strong>1. MLP: The Universal Manifold Operator with No Structural Priors</strong></h3> <p>The MLP treats the input space \(R^D\) as a flat Euclidean space, utilizing hierarchical affine transformations and non-linear activation functions to indiscriminately fold, twist, and stretch the entire input space. According to the Universal Approximation Theorem, given sufficient neurons, an MLP can approximate any continuous function. Theoretically, this implies it can transform a manifold of any topological structure into a linearly separable form.</p> <ul> <li> <p><strong>The Worst Operator</strong>: The MLP structure embeds almost no Inductive Bias. Its core assumption is “smoothness”—that similar inputs yield similar outputs. Mathematically, this requires the learned function to satisfy the Lipschitz continuity condition: \(∥f(x)-f(y)∥≤K∥x−y∥\). However, in high-dimensional space \(R^D\), without specific geometric priors, guaranteeing this smoothness requires a sample size \(N\) that grows exponentially with dimension \(D\). Furthermore, the metric based on Euclidean distance \(∥x−y∥_2\) fails in high-dimensional space, as distances between all point pairs tend to converge. This <strong>assumption of global spatial isotropy</strong> ignores the complexity of high-dimensional manifold structures and is the root cause of its inefficiency. Consequently, massive use of MLPs often leads to suboptimal performance.</p> </li> <li> <p><strong>The Best Operator</strong>: Conversely, the near-absence of Inductive Bias means MLP has no requirements for input data distribution, possessing the capability to fold and project all manifolds. As a rigid transformation operator, MLP does not alter the data’s topological structure. Therefore, in cross-modal feature fusion (direct alignment of embeddings) and most downstream heads (where the feature space is sufficiently flat), MLP becomes the optimal (and most universal) choice. This has led to minimalist approaches like LLaVA.</p> </li> </ul> <h3 id="2-cnn-introduction-of-euclidean-group-symmetry"><strong>2. CNN: Introduction of Euclidean Group Symmetry</strong></h3> <p>The success of CNNs stems from explicitly exploiting the <strong>Geometric Priors</strong> of natural image manifolds:</p> <ul> <li> <p><strong>Local Connectivity</strong>: Assumes the manifold possesses local topological structure; pixel correlation decays with distance.</p> </li> <li> <p><strong>Weight Sharing</strong>: Assumes the geometry of the tangent space is uniform across the manifold. The manifold \(M\) is invariant under the translation group \(SE(2)\), i.e., \(f(T(x))=f(x)\) (invariance) or \(f(T(x))=T′(f(x))\) (equivariance).</p> </li> </ul> <p>As a spatially local operator, CNN explicitly hard-codes the <strong>symmetry</strong> of the manifold into the network structure. It performs “low-pass filtering” in the local neighborhood of the input manifold, attenuating high-frequency noise and unstable directions, thereby making the representation closer to the low-dimensional structure. This can be approximated as CNN performing multiple equidistant foldings and distortions on the entire manifold simultaneously.</p> <p>However, CNNs retain the Euclidean geometric metric. When the data manifold has non-zero curvature (e.g., spherical projection data, non-Euclidean graph data), the translation invariance assumption fails. CNNs cannot effectively capture long-range dependencies because, on a curved manifold, the “straight line” shortest path becomes a geodesic, which fixed-size convolution kernels cannot cover.</p> <h3 id="3-rnn-dynamical-system-trajectories-on-state-manifolds"><strong>3. RNN: Dynamical System Trajectories on State Manifolds</strong></h3> <p>RNN models the data manifold as a Dynamical System evolving over time:</p> \[h_t=σ(W_h h_{t−1} + W_x x_t)\] <p>This is essentially the discretized Euler integration of the ordinary differential equation \(\frac{dh}{dt}=f(h,x)\). The RNN is a temporal recursive operator attempting to learn the vector field of the manifold’s tangent space. Each hidden state \(h_t\) is a coordinate point on the manifold, and the weight matrix \(W\) defines the Flow on the manifold. The learning objective of RNN is not to memorize context, but to learn a hidden state manifold \(S\) and its evolutionary laws, such that task-relevant variables form low-dimensional, predictable trajectories on \(S\), while irrelevant perturbations are compressed into the normal direction and gradually attenuated.</p> <p>The primary issue with RNN is the use of the same weight matrix \(W\) at every step. This enforces an assumption that the manifold is <strong>flat</strong>, i.e., the <strong>tangent space is identical at every location</strong>. However, real semantic manifolds often possess complex curvature. When sequences are long, the actual geometric transformation (the product of Jacobian matrices) leads to exponential explosion or decay of eigenvalues and gradients due to curvature accumulation. RNN attempts to approximate a continuously changing tangent space transformation with a fixed linear operator, which is mathematically ill-posed.</p> <p><strong>Alternative Perspective</strong>:</p> <p>If time \(t\)is viewed as an independent dimension, RNN treats the manifold as <strong>one or more static curves</strong> in a high-dimensional Euclidean space \(R^{D+1}\)defined by parameter \(t\). The hidden state \(h_t\) effectively encodes the tangent space and historical trajectory information at a point \((x_t,t)\) on the manifold. The recursive formula above is geometrically equivalent to path integration along a curve on the manifold surface. RNN attempts to define a vector field that, by advancing via tangent vectors along the \(t\) axis, progressively delineates the manifold’s shape.</p> <p>In this static space, RNN forcibly assumes the manifold is <strong>simply connected</strong> and <strong>sequentially dependent</strong>. It must traverse the manifold strictly along the gradient direction of \(t\). If the manifold is curled in high-dimensional space such that \(t_i\) and \(t_{i+k}\) are extremely close in Euclidean distance but far apart in geodesic distance, RNN must traverse the entire lengthy geodesic to establish a connection. Moreover, relying on the continuous accumulation of local linear approximations of tangent vectors means that once a tangent space estimation deviates at any point (gradient vanishing/exploding), this geometric distortion is amplified exponentially along the path, leading to a collapse in the cognition of the manifold’s global topology. In summary, RNN forcibly reduces a static geometric structure to a one-dimensional path problem, discarding the non-local geometric properties of the manifold in high-dimensional space.</p> <h3 id="4-mamba-ssm-optimal-control-on-continuous-manifolds"><strong>4. Mamba (SSM): Optimal Control on Continuous Manifolds</strong></h3> <p>Mamba (and the underlying S4/S6 theory) is a geometric correction to RNN. It retains the Dynamical System perspective but introduces <strong>HiPPO Matrix Theory and Selective Scan</strong>.</p> \[h′(t)=Ah(t)+Bx(t)\] \[y(t)=Ch(t)\] <p>The special construction of the HiPPO matrix \(A\) ensures that the state \(h_t\) is the optimal projection of all past input manifold history onto an orthogonal polynomial basis. It solves the RNN’s “forgetting” problem. Simultaneously, Mamba introduces \(B(x)\), \(C(x)\), and \(Δ(x)\), making the flow field on the manifold a function of input \(x\). This extends the RNN from a Linear Time-Invariant (LTI) system to a <strong>Linear Time-Variant (LTV)</strong> system.</p> <p>However, even with these optimizations, the system’s information compression remains lossy. Disregarding the advantage of linear complexity, its effectiveness in discrete graph matching tasks is often inferior to the Transformer, and its handling of non-causal data is less intuitive than Attention.</p> <h3 id="5-transformer-adaptive-graph-structure-based-on-dynamic-metrics"><strong>5. Transformer: Adaptive Graph Structure Based on Dynamic Metrics</strong></h3> <p>Initially, the Transformer was viewed as a sequence model, but ignoring the temporal information injected by \(PE\), it is essentially a set-based dynamic Graph Neural Network. The Transformer treats the “data manifold” as a Complete Graph, where the model learns the edge weights itself. It is no longer constrained by neighborhood definitions in Euclidean space, enabling it to handle non-grid data.</p> <p><strong>Self-Attention: Data-Dependent Riemannian Metric</strong></p> <p>In manifold learning, the core challenge is defining the distance between two points on the manifold. CNN assumes a fixed Euclidean distance (pixel adjacency implies correlation), and RNN assumes temporal distance. The Transformer discards these fixed metrics via the self-attention mechanism, learning a <strong>Data-Dependent Metric Tensor</strong>. The attention metrics essentially construct a <strong>dynamic adjacency matrix</strong> using the inner product as a kernel function (Riemannian metric). Unlike the isotropy of Euclidean distance, Attention is highly anisotropic. It dynamically adjusts the direction of the tangent space based on Context, allowing the model to ignore Tokens that are distant in sequence position but adjacent on the semantic manifold.</p> <p>Compared to CNN’s local expansion and RNN’s path integration, the Transformer can establish “wormholes” on the manifold via the Attention mechanism, directly connecting two points with extreme geodesic distances. This eliminates noise caused by curvature accumulation, allowing gradients to propagate losslessly across the manifold.</p> <p><strong>Multi-Head Mechanism: Multiple Sub-Manifold Projections</strong></p> <p>From a manifold geometry perspective, a high-dimensional semantic manifold \(M\) is often the Cartesian product of multiple Sub-manifolds:\(M \approx M_{syntax} \times M_{semantic} \times M_{tone}...\). For example, one Head might capture the sub-manifold of syntactic structure (subject-verb-object relations), while another captures the sub-manifold of coreference resolution (pronouns and their referents). Multi-Head Attention allows the model to compute geometric relations in different tangent subspaces in parallel, finally recovering the complete manifold structure via linear projection and concatenation.</p> <p><strong>In summary, the Transformer’s prior actually weakens existing biases. It pays a computational cost of \(O(N^2)\) in exchange for the ability to capture manifolds of arbitrary topological structure.</strong> This is why it requires massive data; it must learn the manifold’s topology from scratch, unlike CNNs or RNNs which possess inherent locality priors.</p> <h2 id="ii-scaling-law-and-emergence"><strong>II. Scaling Law and Emergence</strong></h2> <p>Architecturally, LLMs (like GPT-4, LLaMA) differ little from the original Transformer; the primary difference is scale. Under the Manifold Hypothesis, the shift from small to large models is not merely quantitative accumulation but a qualitative change in manifold topology, coverage density, and connectivity.</p> <h3 id="1-scaling-law"><strong>1. Scaling Law</strong></h3> <p>In deep learning, Loss essentially measures the distance between the manifold learned by the model and the true data manifold. The Scaling Law describes the power-law decrease of Loss with respect to compute \(C\), parameters \(N\), and data \(D\): \(L(N) \propto N^{-\alpha}\).</p> <ul> <li> <p><strong>Increasing Parameters \(N\) (Reducing Bias):</strong> The Scaling Law suggests that as \(N\) increases, the model’s ability to fit high-frequency curvature rises according to a power law. Small models can only learn the global skeleton of the manifold, i.e., the principal components. At this stage, Loss drops rapidly. As \(N\) increases, the model begins to wrap around high-frequency regions with extreme curvature on the manifold—the rare, complex long-tail samples.</p> </li> <li> <p><strong>Increasing Data \(D\)(Reducing Variance):</strong> According to coverage number theory, covering a \(d\)-dimensional manifold with precision \(\epsilon\) requires sample size\(M \propto (1/\epsilon)^d\). The Scaling Law effectively reveals the decay rate of approximation error as sample density increases for a specific \(d\). This explains why image generation (high \(d\)) is harder to scale than text classification (low \(d\)). The existence of the Scaling Law proves that deep networks are indeed performing manifold learning, not simple memorization. If it were memorization, the Loss curve would not exhibit this power-law distribution.</p> </li> </ul> <p>From the Foundation Model perspective, the training of an LLM is the ultimate approximation of the language manifold.</p> <h3 id="2-emergence-phase-transition-on-the-manifold"><strong>2. Emergence: Phase Transition on the Manifold</strong></h3> <p>If we view data distribution as a manifold, learning is the process of establishing connectivity upon it.</p> <ul> <li> <p><strong>Small Models</strong>: The model learns dispersed local neighborhoods on the manifold but fails to establish correct mappings between them. The model cannot perform multi-step reasoning because the inference path is broken.</p> </li> <li> <p><strong>Critical Point</strong>: When parameter count \(N\) and training data \(D\) exceed a certain threshold, the model’s coverage density on the manifold reaches the percolation threshold. Dispersed local knowledge suddenly connects into a globally consistent graph.</p> </li> <li> <p><strong>Emergence</strong>: At this point, the model can not only interpolate but also perform transitive composition on the manifold. For instance, knowing A→B and B→C leads to the emergence of A→C capability. Macroscopically, this manifests as a sudden jump in performance (similar to phase transitions in complex physical systems).</p> </li> </ul> <p>Emergence is often accompanied by geometric reconstruction (linearization and disentanglement) of the representation space. Before the phase transition, different concepts are entangled and twisted on the manifold, inseparable by linear layers. After the transition, the model learns to unfold the curved manifold into a high-dimensional Euclidean space, making complex semantic relations linearly separable. Acquiring this unfolding capability often requires achieving certain depth and width—precisely the moment emergence occurs.</p> <p><strong>Why can’t other architectures (CNN/RNN) achieve the same degree of emergence?</strong></p> <p>The root cause remains <strong>Inductive Bias.</strong></p> <p>RNN forces all historical information into a fixed-dimension state vector \(h_t\). For complex manifold trajectories, this equates to projecting a high-dimensional manifold into a low-dimensional space, inevitably leading to <strong>information loss and Singularities</strong>. As sequences lengthen and trajectories diverge, the model cannot maintain the global geometric structure of the manifold with finite memory, thus failing to emerge long-range reasoning capabilities. While CNN is efficient, its receptive field grows linearly. Covering two distant associated points on the manifold requires stacking extremely deep networks, leading to optimization difficulties. More importantly, CNN’s weight sharing assumes identical geometric properties across the manifold, limiting its ability to handle non-stationary semantic manifolds.</p> <p>Furthermore, the Transformer’s Attention is the product of input and weights, or even the quadratic form of the input itself ($Q K^T$). This makes it essentially a second-order (or higher) network, whereas other architectures are mostly first-order accumulations. High-order interactions allow the Transformer to dynamically adjust computation weights based on context. This in-context learning capability is difficult for fixed-weight RNN/CNNs to possess.</p> <h2 id="iii-efficient-modeling-of-manifolds"><strong>III. Efficient Modeling of Manifolds</strong></h2> <p>Even by weakening inductive bias, the Transformer gains context-adaptive modeling capabilities. However, this adaptation currently manifests as adjustments for input/output tokens within a unified data manifold, rather than model-level adaptation for different data distributions/manifolds. If we had infinite labor, data, and compute, we could train a specific small-scale Transformer for every sub-task instead of brute-force fitting a billion-parameter large model. Many current architectural optimizations for Transformers are implicitly doing this. For example, MoE partitions regions in FFN memory, while Sparse/Gated Attention establishes highly flexible and sparse connections between coordinates on the manifold.</p> <h3 id="1-moe"><strong>1. MoE</strong></h3> <p>The essence of MoE is acknowledging that using a single, globally shared Dense Model to approximate a high-dimensional manifold with extremely complex topological structure and drastic curvature changes is mathematically inefficient and unstable. If the real data distribution consists of multiple sub-manifolds, a Dense Model learns a single operator under a global unified coordinate system (analogous to a second-order MLP); an MoE model learns multiple local operators (covering different sub-manifold regions) plus a router (learning which region an input token belongs to and which local operators to invoke).</p> <p><strong>Why is MoE suitable for the Long Tail and Multi-Domain aspect of Foundation Models?</strong></p> <p><strong>Long-tail samples</strong> often fall into regions rarely visited by the Dense Model, equivalent to sparse branches or small fragments of the sub-manifold. Simultaneously, a Dense Model with a fixed compute budget struggles to maintain high-resolution approximation across all regions. MoE allocates resolution on demand: letting specific experts handle specific regions, thereby improving coverage of multi-domain structures under the same token compute budget.</p> <h3 id="2-sparse-attention"><strong>2. Sparse Attention</strong></h3> <p>Traditional Attention builds a graph and performs diffusion/kernel smoothing on the token manifold. If token representations lie on a low-dimensional manifold, the most effective information often comes from manifold neighbors or a few cross-region shortcuts. Fully connected attention introduces massive non-manifold noise connections (long-distance, semantically unrelated token interactions); thus, effective mixing does not require full connectivity. The core of Sparse Attention is approximating the full connection in traditional Attention as a sparse graph:</p> <ul> <li> <p><strong>Top-k / kNN Sparsification</strong>: Retain only the \(k\) edges with maximum similarity for each query (manifold neighbors).</p> </li> <li> <p><strong>Block Sparse / Local Window</strong>: Prior assumption that neighbors are also local in sequence position (suitable for local dependencies).</p> </li> <li> <p><strong>Budget Adaptive Sparsity</strong>: Different sparsity levels for different tokens and different stages (prefill vs decode).</p> </li> </ul> <h3 id="3-gated-attention"><strong>3. Gated Attention</strong></h3> <p>The recently emerging Gated Attention goes beyond fine-tuning the attention matrix (which often introduces new inductive biases) to directly adaptively controlling the projected vector field. The Gated mechanism introduces a gating signal \(g \in [0,1]^d\) to filter the update vector dimension-wise. Geometrically, this is orthogonal decomposition and suppression of tangent vectors. The Gate identifies and suppresses noise components perpendicular to the current task sub-manifold, retaining only effective components along the geodesic direction. Furthermore, the gating mechanism is most effective when applied to the Q vector, stemming from the rank elevation of the projection matrix brought by sparsity.</p> <p>When processing long sequences, Gated Attention dynamically adjusts the decay rate of historical information and avoids Attention Sinks. This is equivalent to dynamically adjusting inertia based on the manifold’s local curvature. In flat regions of the manifold (semantic coherence), the Gate allows long-distance information transmission; in regions with curvature mutations (semantic shifts), the Gate rapidly truncates historical dependencies and resets the trajectory direction.</p> <p>These architectural optimizations transcend stabilizing the training process or enhancing feature representation itself. Deeper reasoning often corresponds to <strong>more abstract embeddings and increased information density of single embeddings</strong>. MoE and Sparse/Gated Attention provide the structural foundation for such high signal-to-noise ratio representations. Supported by training data (higher quality) and training methods (deeper RL), the chain-of-thought/graph built by such sparse routing-like mechanisms will demonstrate greater potential. Understood at this level, <strong>the sparsity of thought reflects the model’s level of intelligence to some extent</strong>.</p> <h2 id="iv-true-and-false-reasoning"><strong>IV. True and False Reasoning</strong></h2> <h3 id="1-in-context-learning-icl"><strong>1. In-Context Learning (ICL)</strong></h3> <p>Current ICL in LLMs is essentially a mathematical abstraction of dynamic localization and interpolation of high-dimensional data within a low-dimensional topological structure. ICL is not “learning” new knowledge but retrieving, locating, and locally linearizing the low-dimensional manifold structures constructed during pre-training.</p> <p>In the inference phase, the Transformer uses examples in the Prompt (acting geometrically as anchors on the manifold) to dynamically locate a specific task sub-manifold in the latent space. The Attention mechanism effectively calculates the projection of the input Query onto the tangent space of this sub-manifold. The model merely locks onto a local coordinate system within the vast, learned manifold structure via the Prompt.</p> <p>The forward inference process of the Transformer is mathematically equivalent to gradient descent updates on a loss function defined by context examples, performed in parameter space or activation space. Given context, the model does not update physical weights \(W\) but simulates the process of finding the optimal solution on \(M_{task}\) by changing internal activation states. This makes ICL appear as local fine-tuning within specific regions of the manifold.</p> <p>However, ICL cannot perform true reasoning or create new knowledge. It can only interpolate within the convex hull or neighborhood of the pre-training manifold. If the logic required for the task is completely orthogonal to the pre-training manifold (i.e., Out-of-Distribution), ICL is bound to fail or hallucinate. Furthermore, as context length increases, conflicting or noisy examples can cause unstable localization of activation points on the manifold, or even collapse into incorrect sub-manifold regions.</p> <h3 id="2-cot-path-planning-with-explicit-symbols"><strong>2. CoT: Path Planning with Explicit Symbols</strong></h3> <p>From the rigorous perspective of the Manifold Hypothesis, Chain of Thought is not the emergence of reasoning, but a geometric strategy to reduce mapping curvature and perform geodesic interpolation.</p> <p>In existing LLMs, for simple tasks, input \(x\)and output\(y\) are close on the manifold, or the manifold is locally flat. In this case, single-step reasoning \(y=f(x)\) is effective because it can be approximated by simple linear interpolation or shallow non-linear transformation. However, for complex tasks, although \(x\) and \(y\) are both on the manifold, the geodesic distance between them is immense, and the manifold structure is highly curled, non-convex, or even contains topological holes. If we force the model to directly predict \(P(y \mid x)\), the model attempts to walk a straight line connecting \(x\) and \(y\) in the ambient space. But this straight line often cuts through OOD regions outside the manifold, leading to hallucinations or logical breaks.</p> <p>CoT forces the model to generate intermediate steps \(z_1, z_2, ..., z_n\) between \(x\) and \(y\). This effectively decomposes an extremely difficult global mapping problem into a series of local mapping problems with low Lipschitz constants, explicitly eliminating uncertainty. The token sequence generated by CoT is a discretized geodesic path on the manifold surface.</p> <h3 id="3-latent-cot-returning-to-continuous-manifold-dynamics"><strong>3. Latent CoT: Returning to Continuous Manifold Dynamics</strong></h3> <p>However, human language is a low-dimensional, quantized projection of the thought manifold. Forcing a model to output natural language for reasoning is equivalent to forcing continuous neural network signals through a low-bandwidth Argmax discretization layer. Simultaneously, many intuitive, fuzzy intermediate states cannot be precisely captured by discrete vocabulary. <strong>This quantization noise accumulates in long-chain reasoning, leading to reasoning drift.</strong></p> <p>Latent CoT attempts to remove the constraint of discrete Tokens, evolving trajectories directly in Latent Space. In this case, within Latent Space, the model can maintain a superposition state of being both A and B until the final moment of inference, when it collapses into a discrete output. This avoids error propagation caused by premature discretization decisions. Additionally, a single Token can only transmit \(log_2∥V∥\) bits of information (where \(∥V∥\) is vocabulary size), whereas a \(d\)-dimensional FP16 vector can theoretically transmit far more information. Latent CoT exploits this high-dimensional broadband channel to transmit complex reasoning states.</p> <p>This internal thinking essentially increases the depth of the computational graph. From a manifold perspective, this involves progressively stretching and untangling the originally entangled manifold through multiple composite function transformations until it becomes linearly separable.</p> <p>For Latent CoT, since there is no explicit Ground Truth text, training methods are shifting from SFT to RL. The objective function is no longer predicting the next Token but maximizing the accuracy of the final answer. The model is encouraged to freely explore paths in the latent space. Research finds that the Latent Thoughts learned by the model often exhibit feature distributions incomprehensible to humans—precisely proving that it has broken through the low-dimensional manifold limits of human language and found superior Shortcuts.</p> <p><strong>But is reasoning based on Chain of Thought general reasoning?</strong></p> <p>The reasoning demonstrated by current LLMs is mathematically primarily <strong>local interpolation</strong> on high-dimensional manifolds. The essence of the Scaling Law is that as parameters increase, the sampling density of the manifold rises exponentially, causing the probability of a test sample falling into the \(\epsilon\)-neighborhood of a training sample to approach 1. Human thinking, however, possesses the capability of extrapolation off the manifold. Humans can establish new logical connections in the holes of the data manifold or in directions completely orthogonal to the manifold.</p> <p>Additionally, human language is a <strong>low-dimensional, lossy, highly compressed projection</strong> of the physical world. Humans rarely expand their understanding of the real world solely using language; even theorems and conjectures derived from mathematics/physics require experimental verification in the real world to be widely accepted. LLMs attempt to reconstruct \(M_{world}\) via \(M_{language}\), i.e., building a world model. But since this projection is not bijective, reverse-engineering the world from language has infinite solutions. Therefore, interaction with the environment remains indispensable.</p> <p>Finally, existing large models, even if adaptive, remain static. When data distribution (manifold structure) changes, without retraining or fine-tuning, they will still hit the OOD barrier. Catastrophic forgetting caused by retraining and fine-tuning remains a hurdle difficult to overcome (hence the recent surge in continual learning). Without dynamics, humanity is destined to burn astronomical amounts of capital and electricity in the repeated training of models.</p> <h2 id="epilogue"><strong>Epilogue</strong></h2> <p>I have written too much to ramble further.</p> <p>In short, amidst the waves of chasing hotspots, do not forget that gold often already exists in the shadows of the path traveled.</p>]]></content><author><name></name></author><category term="English"/><category term="Tech-Blog"/><summary type="html"><![CDATA[Introduction: Architectural Evolution and the Path Traveled]]></summary></entry><entry><title type="html">流形假设(Manifold Hypothesis)下的思考·二</title><link href="https://edwardleelpz.github.io/%E4%B8%AD%E6%96%87/2025/12/15/manifold-hypothesis-2.html" rel="alternate" type="text/html" title="流形假设(Manifold Hypothesis)下的思考·二"/><published>2025-12-15T00:00:00+00:00</published><updated>2025-12-15T00:00:00+00:00</updated><id>https://edwardleelpz.github.io/%E4%B8%AD%E6%96%87/2025/12/15/manifold-hypothesis-2</id><content type="html" xml:base="https://edwardleelpz.github.io/%E4%B8%AD%E6%96%87/2025/12/15/manifold-hypothesis-2.html"><![CDATA[<h2 id="引言架构的演进与来时的路"><strong>引言：架构的演进与来时的路</strong></h2> <p>很长时间以来，我们一直在期待一个足已取代Transformer或者现有Attention机制的新一代架构。无论是前两年志在整体颠覆Transformer的Mamba系列还是近期被越来越多提及的Sparse/Gated Attention这样基于已有机制的迭代和优化，研究在不断前进，目标却仍忽远忽近。相比于难以捉摸的未来，也许来时的路会更加清晰一些。</p> <h2 id="一从mlp到transformer"><strong>一、从MLP到Transformer</strong></h2> <p>从流形假设的角度，所有的经典架构都可以被视为带有不同Inductive Bias的从卷曲流形到平坦特征空间的拓扑变换。</p> <h3 id="1-mlp无结构先验的通用流形算子"><strong>1. MLP：无结构先验的通用流形算子</strong></h3> <p>MLP 将输入空间 \(R^D\) 视为平坦的欧几里得空间，利用层级化的仿射变换和非线性激活函数，对整个输入空间进行无差别的折叠、扭曲和拉伸。 根据 Universal Approximation Theorem，只要有足够的神经元，MLP 可以逼近任何连续函数。这意味着它理论上可以将任何拓扑结构的流形变换为线性可分形态。</p> <ul> <li> <p><strong>最差的算子</strong>：MLP结构内部几乎没有内嵌任何Inductive Bias，其核心假设是“平滑性”，即相近的输入产生相近的输出。数学上，这要求学习的函数满足Lipschitz连续条件：\(∥f(x)-f(y)∥≤K∥x−y∥\) 。然而，在高维空间 \(R^D\) 中，若没有特定的几何先验，要保证这种平滑性，所需的样本数量 \(N\) 随维度 \(D\) 呈指数增长。此外，这种基于欧氏距离 \(∥x−y∥_2\) 的度量在高维空间中失效，所有点对之间的距离趋于一致。这种<strong>全空间各向同性的假设</strong>忽视了高维流形结构的复杂性，是其效率低下的根本原因。因此，MLP的大规模使用总是会导致最差的性能。</p> </li> <li> <p><strong>最好的算子</strong>：从另一个角度讲，几乎没有Inductive Bias意味着对于输入数据的分布没有任何要求，MLP具备对于所有流形的折叠与投影能力。同时作为刚性变换算子， MLP不改变数据的拓扑结构。因此，在跨模态特征融合（embedding的直接对齐）以及大多数downstream head（特征空间足够平坦）中，MLP成为了最优（最通用）的选择。这也造就了诸如LLaVA等大道至简的方法。</p> </li> </ul> <h3 id="2-cnn欧氏群对称性的引入"><strong>2. CNN：欧氏群对称性的引入</strong></h3> <p>CNN 的成功源于它显式地利用了自然图像流形的<strong>Geometric Priors</strong>：</p> <ul> <li><strong>局部连接</strong>：它假设流形具有局部拓扑结构，像素的相关性随距离衰减。</li> <li><strong>权值共享</strong>：它假设流形上各处的切空间几何性质是均匀的，流形 \(M\) 对平移群 \(SE(2)\) 是不变的，即： \(f(T(x))=f(x)\) （不变性）或 \(f(T(x))=T′(f(x))\) （等变性）。</li> </ul> <p>CNN作为空间局部算子，显式地在网络结构中硬编码了流形的<strong>对称性</strong>，在输入流形的局部邻域做“低通滤波”，削弱高频噪声与不稳定方向，从而让表示更接近低维结构。这可以近似理解为CNN在对整个流形同时及进行多个等间距的折叠和扭曲。</p> <p>但是卷积神经网络依然保留了欧氏几何度量，当数据流形具有非零曲率（如球面投影数据、非欧几何图数据）时，CNN的平移不变性假设失效，导致其无法有效捕捉长程依赖，因为在弯曲流形上，“直线”最短路径变成了测地线，而固定大小的卷积核无法覆盖测地线距离。</p> <h3 id="3-rnn状态流形上的动力系统轨迹"><strong>3. RNN：状态流形上的动力系统轨迹</strong></h3> <p>RNN将数据流形建模为一个随时间演化的Dynamical System：</p> \[h_t=σ(W_h h_{t−1} + W_x x_t)\] <p>这本质上是常微分方程 \(\frac{dh}{dt}=f(h,x)\) 的离散化欧拉积分。RNN 是一个时间递推算子，试图学习流形的切空间向量场。每一个隐状态 \(h_t\) 都是流形上的一个坐标点，权重矩阵 \(W\) 定义了流形上的Flow。RNN 的学习目标不是记住context，而是学到一个隐状态流形 \(S\) 及其上的演化规律，使得任务相关变量在 \(S\) 上形成低维、可预测的轨迹，且不相关扰动被压到法向方向并逐步衰减。</p> <p>RNN 的主要问题在于在每一步使用相同的权重矩阵 \(W\) 。这相当于强行假设流形是<strong>平坦的</strong>，即<strong>切空间在任何位置都相同</strong>。然而，真实的语义流形往往具有复杂的曲率。当序列很长时，真实的几何变换（雅可比矩阵的连乘）会因为曲率累积而导致特征值及其梯度的指数级爆炸或衰减。RNN 试图用一个固定的线性算子去逼近不断变化的切空间变换，这在数学上是病态的。</p> <p><strong>另一个思路</strong>：</p> <p>如果将时间 \(t\) 视为独立维度，RNN 将流形视为由参数 \(t\) 定义的高维欧几里得空间 \(R^{D+1}\) 中<strong>一条或多条静态曲线</strong>。隐状态 \(h_t\) 实际上是对流形上某一点 \((x_t,t)\) 处的切空间及其历史轨迹信息的编码。 而上述递归公式在几何上等价于沿着流形表面的曲线进行路径积分。RNN 试图定义一个向量场，通过沿 \(t\) 轴的切向量推进，逐步描绘出流形的形状。</p> <p>在这种静态空间中，RNN 强行假设流形是<strong>单连通</strong>且<strong>顺序依赖</strong>的。它必须严格沿着\(t\)的梯度方向遍历流形。如果流形在高维空间中存在卷曲使得 \(t_i\) 和 \(t_{i+k}\) 在欧氏距离上极近，但在测地线距离上极远，RNN 必须走完漫长的测地线才能建立联系。此外，由于是基于切向量的局部线性近似不断累积，一旦在某处的切空间估计出现偏差（梯度消失/爆炸），这种几何畸变会沿着路径指数级放大，导致对流形全局拓扑的认知坍塌。综上，RNN 将静态几何结构强行降维为一维路径问题，丢弃了流形在高维空间中的非局部几何特性。</p> <h3 id="4-mamba-ssm连续流形的优化控制"><strong>4. Mamba (SSM)：连续流形的优化控制</strong></h3> <p>Mamba（及其背后的S4/S6理论）是对RNN的几何修正。 它沿用了 Dynamical System 的视角，但引入了<strong>HiPPO矩阵理论和Selective Scan</strong>。</p> \[h′(t)=Ah(t)+Bx(t)\] \[y(t)=Ch(t)\] <p>HiPPO矩阵 \(A\) 的特殊构造，保证了状态\(h_t\)是过去所有输入流形历史在正交多项式基底上的最优投影。它解决了RNN“记不住”的问题。同时Mamba引入了 \(B(x)\) ， \(C(x)\) ， \(Δ(x)\) ，使得流形上的流场是输入 \(x\) 的函数。这将RNN这一线性时不变系统（LTI）扩展为了<strong>线性时变系统（LTV）</strong>。</p> <p>然而，即便做出了上述优化，整个系统的信息压缩依然是有损的，如果不考虑线性复杂度的优势的话，其在处理离散图匹配类型任务时往往效果不如Transformer，对非因果数据处理也不如Attention直观</p> <h3 id="5-transformer基于动态度量自适应图结构"><strong>5. Transformer：基于动态度量自适应图结构</strong></h3> <p>在研究初期，人们大多认为Transformer是序列模型，但如果忽略 \(PE\) 注入的时序信息，其本质是一个基于集合的动态图神经网络。Transformer将“数据流形”视为一个Complete Graph，由模型自己去学习边的权重。它不再受限于欧氏空间的邻域定义，因此能处理非网格数据。</p> <p><strong>自注意力：数据驱动的黎曼度量</strong></p> <p>在流形学习中，核心难题是如何定义流形上两点之间的距离。CNN假设了固定的欧氏距离（像素相邻即相关），RNN假设了时间距离。Transformer通过自注意力机制抛弃了这些固定度量，转而学习一个<strong>Data-Dependent Metric Tensor</strong>。其中的attention metrics实际上是在构建一个以内积为核函数（黎曼度量）的<strong>动态邻接矩阵</strong>。不同于欧氏距离的各向同性，Attention 是高度各向异性的。它根据Context动态调整切空间的方向，使得模型能够忽略序列位置上相距甚远但在语义流形上相邻的 Token。</p> <p>相比于CNN只能在流形上局部扩展和RNN的沿时序路径积分，Transformer可以通过Attention机制在流形上建立“虫洞”，直接连接测地距离极远的两个点。这消除了曲率累积带来的噪声，使得梯度可以在流形上无损传播。</p> <p><strong>多头机制：多重子流形投影</strong></p> <p>从流形几何角度，高维语义流形 \(M\) 往往是由多个Sub-manifolds的笛卡尔积组成的： \(M≈M_{syntax}×M_{semantic}×M_{tone}...\) 。例如一个 Head 可能捕捉句法结构的子流形（主谓宾关系），另一个 Head 可能捕捉指代关系的子流形（代词与其指代对象）。 Multi-Head Attention 允许模型在不同的切子空间并行地计算几何关系，最后通过线性投影拼接，恢复出完整的流形结构。</p> <p><strong>综上，Transformer的先验其实反而弱化了已有偏置。它付出了 \(O(N^2)\) 的计算代价，换取了捕捉任意拓扑结构流形的能力</strong>。这也是为什么它需要海量数据，即它必须从零开始学习流形的拓扑，而不能像CNN，RNN那样提前获得局部性先验</p> <h2 id="二scaling-law与涌现"><strong>二、Scaling Law与涌现</strong></h2> <p>从架构层面看，LLM（如 GPT-4, LLaMA）与最初的 Transformer并无本质区别，主要差异在于规模。流形假设的视角下，从小模型到大模型的转变，不仅是量的积累，更是流形拓扑结构、覆盖密度与连通性的质变。</p> <h3 id="1-scaling-law"><strong>1. Scaling Law</strong></h3> <p>在深度学习中，Loss 本质上衡量的是模型学习到的流形与真实数据流形之间的距离。Scaling Law 描述了 Loss 随计算量 \(C\)、参数量 \(N\)、数据量 \(D\) 的幂律下降关系： \(L(N)∝N^{−α}\) 。</p> <ul> <li><strong>增加参数 \(N\)（降低 Bias）：</strong> Scaling Law 表明：随着 \(N\) 增加，模型拟合高频曲率的能力呈幂律上升。小模型只能学习流形的整体骨架，即流形的主成分。此时Loss下降快。随着 \(N\) 增加，模型开始能够包裹住流形上曲率极大的高频区域，即那些罕见的、复杂的长尾样本。</li> <li><strong>增加数据 \(D\)（降低 Variance）：</strong> 根据覆盖数理论，为了以精度 \(ϵ\) 覆盖一个 \(d\) 维流形，所需样本数 \(M∝(1/ϵ)^d\) 。Scaling Law 实际上揭示了在特定的 \(d\) 下，逼近误差随样本密度增加的衰减速率。这解释了为什么图像生成（高 \(d\)）比文本分类（低 \(d\)）更难scale。Scaling Law 的存在证明了深度网络确实是在进行流形学习，而不是简单的记忆。如果是记忆，Loss曲线不会呈现这种幂律分布。</li> </ul> <p>从 Foundation Model 的角度，LLM 的训练过程是对语言流形的极致逼近。</p> <h3 id="2-涌现流形上的相变"><strong>2. 涌现：流形上的相变</strong></h3> <p>当我们将数据分布视为流形，学习过程则可被视为在流形上建立连通性的过程。</p> <ul> <li><strong>小模型</strong>：模型学习了流形上分散的局部邻域，但在这些邻域之间没有建立正确的映射关系。此时模型无法完成多步推理，因为推理路径断裂。</li> <li><strong>临界点</strong>：当参数量 \(N\) 和训练数据量 \(D\) 超过某个阈值，模型对流形的覆盖密度达到了渗流阈值。分散的局部知识突然连通成一个全局一致的图谱。</li> <li><strong>涌现</strong>：此时，模型不仅能插值，还能在流形上进行传递性组合。例如，当获知 A→B 和 B→C 后涌现出了 A→C 的能力。这在宏观上表现为性能的突变（类似于物理学复杂系统中的相变）</li> </ul> <p>而涌现往往伴随着表征空间的几何重构（线性化解耦）。在相变前，不同概念在流形上是纠缠扭曲的，线性层无法分离。相变后，模型学会了将弯曲的流形展开到高维欧氏空间中，使得复杂的语义关系变得线性可分。这种展开能力的习得，往往需要达到一定的深度和宽度，这正是涌现发生的时刻。</p> <p><strong>为什么其他结构（CNN/RNN）无法实现同等程度的涌现</strong>？</p> <p>其根本原因依然是<strong>归纳偏置。</strong></p> <p>RNN 强制将所有历史信息压缩进一个固定维度的状态向量 \(h_t\)。对于复杂的流形轨迹，这相当于试图将高维流形投影到低维空间，必然导致<strong>信息丢失和Singularities</strong>。当序列变长，轨迹发散，模型无法通过有限的内存维持流形的全局几何结构，因此无法涌现出长程推理能力。CNN虽然Efficient，但其卷积核的感受野增长是线性的。要覆盖流形上两个相距甚远的关联点，需要堆叠极深的网络，导致优化困难。更重要的是，CNN的权值共享机制假设流形各处几何性质相同，这限制了其处理non-stationary语义流形的能力。</p> <p>此外，Transformer的Attention是输入与权重的乘积，甚至是输入自身的二次型（QKT）。这使得它本质上是一个二阶及以上的高阶网络，而其他架构多为一阶累加。高阶交互允许Transformer根据上下文动态调整计算权重。这种上下文学习能力是固定权重的RNN/CNN难以具备的。</p> <h2 id="三流形的高效建模"><strong>三、流形的高效建模</strong></h2> <p>即便通过弱化归纳偏置，Transformer获得了上下文自适应建模能力。但是这种自适应近表现为对于统一数据流形中的输入输出token的调整，而非为不同的数据分布/流形的模型层面的适配。如果我们有无限的人力，数据和计算资源，那么我们完全也可以对于每一个子任务都训练一个特定小规模的Transformer，而非用一个亿万参数大模型暴力拟合。其实现在很多对于Transformer的架构优化就是在隐式地做这件事，例如MoE是在为FFN中的记忆划分区域，Sparse/Gated Attention则是建立流形上坐标间的高度灵活且稀疏的链接。</p> <h3 id="1-moe"><strong>1. MoE</strong></h3> <p>MoE 的本质是承认用单一的、全局共享的Dense Model去逼近一个拓扑结构极其复杂、曲率变化剧烈的高维流形，在数学上是低效且不稳定的。如果真实数据分布由多个子流形组成，那么一个Dense Model是在学一个全局统一坐标系下的单一算子（类比二阶MLP）；而一个MoE 模型更像是在学多个局部算子（分别覆盖不同的子流形区域）外加一个路由（学习输入 token 属于哪个区域，以及应当调用哪些局部算子）。</p> <p><strong>MoE 为什么适合基座模型的长尾与多域</strong>？</p> <p><strong>长尾样本</strong>往往落在Dense Model很少访问的区域，等价于子流形的稀疏分支或小片段。同时，Dense Model在固定计算预算下，很难同时在所有区域维持高分辨率逼近。而 MoE 能把分辨率按需分配：让特定区域由特定专家承担，从而在同等 token 计算下提升对多域结构的覆盖。</p> <h3 id="2-sparse-attention"><strong>2. Sparse Attention</strong></h3> <p>传统Attention是在在 token 流形上建图并做扩散/核平滑。若 token 表征落在低维流形上，最有效的信息往往来自于流形上的近邻或少数跨区捷径。而全连接带来了大量非流形上的噪声连接（远距离、无语义关联的 Token 交互），因此有效的mixing并不需要对所有节点全连接。Sparse Attention 的核心就是把传统Attention中的全连接近似为稀疏图：</p> <ul> <li>Top-k / kNN 稀疏化：只保留每个 query 的 \(k\) 条最大相似度边（流形近邻）。</li> <li>块稀疏/局部窗口：先验假设近邻在序列位置上也局部（适合局部依赖）。</li> <li>预算自适应稀疏：不同 token、不同阶段（prefill vs decode）用不同稀疏度。</li> </ul> <h3 id="3-gated-attention"><strong>3. Gated Attention</strong></h3> <p>近期兴起的 Gated Attention则是跨越了对于注意力矩阵的微调（上述的微调往往伴随着新的归纳偏置的引入），直接对投影后的向量场进行自适应控制。Gated 机制通过引入门控信号 \(g∈[0,1]^d\) ，对更新向量进行逐维度的过滤。几何上，这是对切向量进行正交分解与抑制。Gate 识别并抑制掉那些垂直于当前任务子流形的噪声分量，仅保留沿测地线方向的有效分量。此外，门控机制作用于Q向量上最为有效，这来自于稀疏性带来的投影矩阵的rank的提升。</p> <p>在处理长序列时，Gated Attention 动态调整历史信息的衰减率且避免了Attention Sink。这等价于根据流形的局部曲率动态调整惯性。在流形平坦区域（语义连贯），Gate 允许信息长距离传输；在曲率突变区域（语义转换），Gate 迅速截断历史依赖，重置轨迹方向。</p> <p>上述这些架构优化其实超越了稳定训练过程或者是提升特征表示能力本身。因为更深层次的推理往往对应着<strong>更为抽象的embedding和单一embedding信息密度的升高</strong>，而MoE和Sparse/Gated Attention则为这样的高信噪比表征提供了结构性基础。当有了训练数据（更高质量）和训练方式（更深层次的RL）的支持，这种稀疏的类路由机制搭建的思维链/图才会展现出更大的潜力。从这个层面理解，<strong>思维的稀疏性一定程度上反映了模型的智能水平</strong>。</p> <h2 id="四真假reasoning"><strong>四、真假Reasoning</strong></h2> <h3 id="1-上下文学习-in-context-learning"><strong>1. 上下文学习 (In-Context Learning)</strong></h3> <p>当前LLM中的ICL本质上是对高维数据在低维拓扑结构中动态定位与插值过程的数学抽象。ICL 并非“学习”新知识，而是对预训练期间已构建的低维流形结构的检索、定位与局部线性化。</p> <p>Transformer 在推理阶段，通过 Prompt 中的示例（在几何上充当了流形上的锚点），在隐空间中动态定位到了一个特定的任务子流形。 Attention 机制实际上是在计算输入 Query 与这个子流形切空间的投影，即模型只是在已习得的庞大流形结构中，通过 Prompt 锁定了局部坐标系。</p> <p>Transformer 的前向推理过程，在数学形式上等价于在参数空间或激活空间上，针对上下文示例定义的损失函数 进行的梯度下降更新。给定上下文时，模型不需要更新物理权重W，而是通过改变内部激活状态，模拟了在 \(M_{task}\) 上寻找最优解的过程。这使得 ICL 表现为在流形特定区域内的局部微调。</p> <p>但是ICL无法进行真正的推理或创造新知识。它只能在预训练流形的凸包内或邻域进行插值。如果任务所需的逻辑完全正交于预训练流形，即 Out-of-Distribution，ICL 必将失效或产生幻觉。同时。随着上下文长度增加，如果示例存在冲突或噪声，会导致激活点在流形上定位不稳，甚至坍缩到错误的子流形区域。</p> <h3 id="2-cot显式符号的路径规划"><strong>2. CoT：显式符号的路径规划</strong></h3> <p>从流形假设的严谨视角来看，Chain of Thought并非是推理涌现，而是一种减小映射曲率与测地线插值的几何策略。</p> <p>在现有的LLM中，对于简单任务，输入 \(x\) 和输出 \(y\) 在流形上距离很近，或者流形在局部是平坦的。此时，单步推理 \(y=f(x)\) 是有效的，因为通过简单的线性插值或浅层非线性变换即可逼近。但是对于复杂任务，\(x\) 和 \(y\) 虽然都在流形上，但它们之间的测地线距离极远，且流形结构高度卷曲、非凸，甚至存在拓扑空洞。如果强行训练模型直接预测 \(P(y∣x)\) ，模型试图在环境空间中走直线连接 \(x\) 和 \(y\)。但这条直线往往穿过了流形之外的OOD区域，这导致了模型产生幻觉或逻辑断裂。</p> <p>CoT 强制模型在 \(x\) 和 \(y\) 之间生成中间步骤 \(z_1,z_2,…,z_n\) 。 这实际上是将一个极其困难的全局映射问题，分解为一系列低Lipschitz常数的局部映射问题，显式地消除了不确定性。CoT 生成的 Token 序列，就是流形表面上一条离散化的测地线路径。</p> <h3 id="3-latent-cot回归连续流形动力学"><strong>3. Latent CoT：回归连续流形动力学</strong></h3> <p>但是人类语言是思维流形的低维、量化投影。强迫模型输出自然语言来进行推理，相当于强迫连续的神经网络信号经过一个低带宽的 Argmax 离散化层。同时许多直觉、模糊的中间状态无法被离散词汇精确捕获。<strong>这种量化噪声在长链条推理中会累积，导致推理漂移</strong>。</p> <p>Latent CoT 试图移除离散Token的约束，直接在Latent Space进行轨迹演化。在这种情况下，在 Latent Space 中，模型可以维持既是A又是B的叠加态，直到推理的最后一刻才坍缩为离散输出。这避免了过早的离散化决策带来的错误传播。另外，一个 Token 只能传递 \(log_2∥V∥\) bits 的信息（ \(∥V∥\) 为词表大小），而一个 \(d\) 维 FP16 向量理论上可以传递的信息量远超于此。Latent CoT 利用了这个高维宽带通道来传递复杂的推理状态。</p> <p>这种内部思考实际上是在增加计算图的深度。从流形角度看，这是通过多次复合函数变换，将原本纠缠在一起的流形逐步拉伸、解开，直到线性可分。</p> <p>对于 Latent CoT，由于没有显式的 Ground Truth 文本，训练方法正从SFT转向RL，即目标函数不再是预测下一个 Token，而是最大化最终答案的准确率。模型被鼓励自由探索隐空间中的路径。研究发现，模型学出的 Latent Thoughts 往往呈现出人类无法理解的特征分布——这恰恰证明了它突破了人类语言的低维流形限制，找到了更优的Shortcuts。</p> <p><strong>但是，基于思维链的推理是通用推理么？</strong></p> <p>目前的LLM表现出的推理，在数学上主要是高维流形上的<strong>局部插值</strong>。Scaling Law 的本质是随着参数增加，流形的采样密度呈指数级上升，使得测试样本落入训练样本 \(ϵ\)-邻域的概率无限趋近于1。而人类的思维具备离流形外推的能力。人类可以在数据流形的空洞处，或者完全正交于流形的方向上建立新的逻辑连接。</p> <p>另外，人类语言是物理世界的一个<strong>低维、有损、高度压缩的投影</strong>。 人类鲜少仅仅使用语言来扩展对于真实世界的理解，即便是从数学/物理推算得到的定理与猜想，也需要现实世界中的实验验证后才会被广泛接受。而LLM 试图通过 \(M_{language}\) 重构 \(M_{world}\)，即建立世界模型。但由于这种投影不是双射，从语言逆推世界存在无穷多解。因此与环境的交互仍是不可或缺的。</p> <p>最后，现有的大模型即便自适应也仍然是静态模型，当数据分布（流形结构）变化时，不经历重训或微调仍然会触及OOD的屏障，而重训和微调造成的灾难性遗忘仍然是难以跨越的阻碍（因此最近continue learning愈发火热）。不具备动态，则人类注定要在模型的反复训练中烧掉天量的资金和电力。</p> <h2 id="结语"><strong>结语</strong></h2> <p>码字太多不想再啰嗦。</p> <p>一言以蔽之，在追寻热点的浪潮中不要忘记，金子大多早已存在在来时的阴影中。</p>]]></content><author><name></name></author><category term="中文"/><category term="Tech-Blog"/><summary type="html"><![CDATA[引言：架构的演进与来时的路]]></summary></entry><entry><title type="html">Reflections on the Manifold Hypothesis - 1</title><link href="https://edwardleelpz.github.io/english/2025/11/25/manifold-hypothesis-1.html" rel="alternate" type="text/html" title="Reflections on the Manifold Hypothesis - 1"/><published>2025-11-25T00:00:00+00:00</published><updated>2025-11-25T00:00:00+00:00</updated><id>https://edwardleelpz.github.io/english/2025/11/25/manifold-hypothesis-1</id><content type="html" xml:base="https://edwardleelpz.github.io/english/2025/11/25/manifold-hypothesis-1.html"><![CDATA[<h2 id="introduction-geometric-order-amidst-high-dimensional-noise"><strong>Introduction: Geometric Order Amidst High-Dimensional Noise</strong></h2> <p>Inspired by Kaiming He’s recent work on JiT, I intend to discuss the Manifold Hypothesis, a topic widely debated in the generative field. While such discussions are common, the hypothesis provides a geometric perspective essential for understanding existing deep learning architectures, offering potential generalization across various tasks and scenarios.</p> <p>The <strong>Manifold Hypothesis</strong> is a cornerstone of deep learning theory. It attempts to explain the remarkable performance of neural networks on extremely high-dimensional data (e.g., images, text, audio). Simply put, the hypothesis posits: <strong>Although real-world data (such as an image) appears to consist of thousands of dimensions \(D\) (pixels), they are actually distributed on a low-dimensional manifold (dimension \(d\), where \(d \ll D\)) embedded within the high-dimensional space.</strong></p> <p>In topology, a manifold locally approximates Euclidean space (like a plane or line) but may possess a complex global geometric structure. Intuitively, imagine a two-dimensional sheet of paper (2D plane): the paper itself is two-dimensional, described by coordinates \((u,v)\). However, if crumpled into a ball and placed in three-dimensional space, an observer perceives it as an object in 3D space described by coordinates \((x,y,z)\). Yet, for an ant situated at \((u,v)\) on the paper, it remains a two-dimensional world. Here, the crumpled paper corresponds to the low-dimensional manifold where data resides within the high-dimensional reality.</p> <p>In the context of deep learning, the Manifold Hypothesis implies several key corollaries:</p> <p><strong>1. Low Degrees of Freedom</strong></p> <p>Despite the massive apparent dimensionality of data, its true degrees of freedom are constrained by physical reality. For instance, a facial image may contain millions of pixels, but its variational degrees of freedom are limited—e.g., pose (pitch/yaw/roll), lighting direction, and facial expression. These degrees of freedom constitute the <strong>intrinsic dimension</strong> of the data. This implies that a model may only need a few dozen dimensions to accurately characterize data features.</p> <p><strong>2. Neural Networks as Manifold Unrollers</strong></p> <p>The essence of classification and regression tasks is the disentanglement of manifolds. In the original high-dimensional space, manifolds of different classes may be entangled like knotted ropes, making them linearly inseparable. <strong>Deep neural networks (particularly deep structures) are viewed as performing non-linear distortions and stretching of space.</strong> Through layer-by-layer coordinate transformations, the curled, entangled manifolds are gradually unfolded until they become flat and linearly separable.</p> <p>Continuing the paper analogy, consider two crumpled and entangled sheets of paper. The neural network functions by performing a series of precise unfoldings (non-linear transformations between layers), carefully smoothing and separating them, and finally drawing a dividing line (classification).</p> <p>The Manifold Hypothesis is not merely theoretical speculation; it is validated in practice:</p> <p><strong>1. Latent Space Interpolation</strong></p> <p>Linear interpolation ($0.5A + 0.5B$) between two facial images A and B in pixel space typically results in a ghostly, unnatural superposition because the interpolated data leaves the manifold, entering the empty void of the high-dimensional space.</p> <p>However, using Generative Adversarial Networks (GANs) or Variational Autoencoders (VAEs) to map images into a low-dimensional latent space, interpolating, and then decoding, yields a smooth transition from face A to face B. This demonstrates that data forms a continuous low-dimensional manifold, where coordinate migration reflects feature transformation.</p> <p><strong>2. Adversarial Examples</strong></p> <p>Adversarial attacks typically involve adding minute perturbations to an image—displacements in the direction of the manifold’s normal vector—causing the data point to detach from the support set or cross the decision boundary, leading to misclassification. Conversely, this indicates that the decision boundary learned by the model closely adheres to the data manifold but is extremely fragile in the manifold’s normal direction.</p> <h2 id="i-the-geometric-evolution-of-deep-learning-paradigms-from-topological-disentanglement-to-unified-field-theory"><strong>I. The Geometric Evolution of Deep Learning Paradigms: From Topological Disentanglement to Unified Field Theory</strong></h2> <p>Scrutinizing different deep learning paradigms reveals they are essentially operating on and utilizing the same manifold structure in distinct ways.</p> <h3 id="1-discriminative-tasks-classification--regression-manifold-disentanglement-and-separation"><strong>1. Discriminative Tasks (Classification / Regression): Manifold Disentanglement and Separation</strong></h3> <p>In the raw pixel space, samples from different classes lie on highly curled and entangled manifolds, inseparable by linear classifiers. Discriminative models, through hierarchical non-linear transformations, act as homeomorphic mapping operators in topology. They do not alter the topological properties of the data but, by stretching and twisting the space (ignoring internal metric structures), focus on maximizing the distance between class manifolds. This is akin to untangling red and blue papers from a chaotic ball until they are flat and linearly separable in the high-level feature space.</p> <h3 id="2-generative-tasks-generative-modeling-manifold-parametrization-and-traversal"><strong>2. Generative Tasks (Generative Modeling): Manifold Parametrization and Traversal</strong></h3> <p>Generative models focus on the geometry and probability density of the manifold itself. Taking Diffusion Models as an example, the denoising process can be viewed as searching for the manifold within a high-dimensional energy landscape. The model learns a Score Function (Gradient Field) indicating “distance from the manifold.” The generation process resembles a random point in high-energy high-dimensional space converging to the surface of the low-dimensional manifold along the gradient field trajectory.</p> <h3 id="3-unified-architecture-energy-minimization-on-sequence-manifolds"><strong>3. Unified Architecture: Energy Minimization on Sequence Manifolds</strong></h3> <p>The current frontier unifies discrimination and generation within a single architecture, such as Transformer-based Next-Token Prediction. From a manifold perspective, the distinction vanishes; both are trajectory extensions on a sequence manifold.</p> <p>Whether the input is “What is this image?” (discrimination) or “Draw a cat” (generation), the model plans a path minimizing the energy function on the manifold surface given a starting point. Classification labels are simply specific discrete nodes on the manifold, while generated content represents continuous paths. This perspective dissolves task boundaries: Large Language Models (LLMs) are essentially constructing a joint semantic manifold, approximating the tangent space direction of the manifold by predicting the next token.</p> <p>The advantage of a unified architecture lies in <strong>Manifold Regularization</strong>: Pure discriminative models focus only on <strong>boundaries</strong>, ignoring <strong>internal structure</strong>, making them fragile to adversarial examples; pure generative models focus on <strong>internal structure</strong> but may lack understanding of <strong>inter-class differences</strong>. The <strong>unified architecture</strong> compels the model to both delineate the manifold (generation) and distinguish it (discrimination), forcing the learned manifold representation to be <strong>both precise (fitting data distribution) and robust (clear boundaries)</strong>.</p> <h3 id="4-multimodal-models-homeomorphic-alignment-of-heterogeneous-manifolds"><strong>4. Multimodal Models: Homeomorphic Alignment of Heterogeneous Manifolds</strong></h3> <p>The image manifold consists of continuous pixel variations, while the text manifold comprises discrete symbol combinations. The core challenge for multimodal models like CLIP or GPT-4o lies in finding conformal mappings between these heterogeneous geometries. The Manifold Hypothesis introduces a central concept here: the <strong>Shared Semantic Manifold</strong>. Images and text are merely different projections of the same semantic entity. Multimodal learning aims to construct a shared latent space where the “image of a cat” and the vector for “Cat” coincide, achieving semantic unification.</p> <p>Furthermore, leveraging the unified architecture, simple cross-modal semantic alignment evolves into cross-modal understanding. In this scenario, the text token “Cat” corresponds not only to the <strong>semantic anchor</strong> of a cat but also aligns closely with low-level visual representations like facial whiskers or fur. This bridges the gaps between different modal manifolds, making the shared semantic manifold smoother and more complete. Consequently, multimodal large models often outperform single-modal expert models in understanding capabilities.</p> <h2 id="ii-deep-reinforcement-learning-control-and-planning-on-dynamic-manifolds"><strong>II. Deep Reinforcement Learning: Control and Planning on Dynamic Manifolds</strong></h2> <p>Introducing temporal dimensions and decision mechanisms extends the Manifold Hypothesis from static geometry to dynamic systems theory, profoundly manifested in Deep Reinforcement Learning (DRL). Unlike Supervised Learning’s treatment of “static” data, DRL deals with dynamic, interactive data streams.</p> <h3 id="1-physical-dimensionality-reduction-of-state-space"><strong>1. Physical Dimensionality Reduction of State Space</strong></h3> <p>The Encoder in DRL is tasked with <strong>projecting high-dimensional observations (e.g., million-dimensional video streams) onto a low-dimensional physical state manifold</strong>. The dimension of this manifold typically equates to the system’s physical degrees of freedom (e.g., joint angles, position coordinates). Effective representation learning must filter out “noise dimensions” irrelevant to dynamics—such as lighting and texture—retaining only the essential coordinates governing system evolution. If the Encoder fails to learn the correct manifold structure, a change in an irrelevant background pixel (far in pixel space but identical on the physical manifold) could lead to drastically different action predictions.</p> <h3 id="2-dynamics-as-vector-fields"><strong>2. Dynamics as Vector Fields</strong></h3> <p>Physical laws define strict <strong>Vector Fields or Flows</strong> on the manifold. An agent’s Policy does not select actions in a vacuum but plans geodesics within a <strong>Feasible Tube</strong> constrained by dynamics on the manifold surface. States cannot jump arbitrarily; they must move in directions permitted by dynamic equations. The training process involves finding an optimal curve leading to high-reward regions.</p> <h3 id="3-riemannian-manifolds-and-natural-gradient-trpo--ppo"><strong>3. Riemannian Manifolds and Natural Gradient (TRPO / PPO)</strong></h3> <p>Typically, we optimize neural network parameters \(θ\). However, in RL, we care about changes in the <strong>policy distribution \(π_θ(a \mid s)\)</strong>. A small step in parameter space \(θ\) (Euclidean distance) can cause drastic changes in policy distribution, leading to Policy Collapse. The parameter space is not the correct geometric space for describing policy changes.</p> <p>Considering the policy distribution, it forms a <strong>Statistical Manifold</strong>. On this manifold, the distance metric shifts from Euclidean distance to <strong>KL Divergence</strong>. TRPO constrains the policy’s <strong>movement distance on the manifold</strong> (KL divergence) to stay within a threshold during updates. Akin to walking on a curved Earth surface, TRPO ensures the model moves along geodesics rather than tunneling through the center. This explains why PPO/TRPO are more stable than vanilla Policy Gradient: they respect the manifold geometry of the policy space.</p> <h3 id="4-manifold-boundaries-and-out-of-distribution-ood-generalization"><strong>4. Manifold Boundaries and Out-of-Distribution (OOD) Generalization</strong></h3> <p>When an agent cannot interact with the environment and must learn from historical data (Offline RL), the Manifold Hypothesis explains the primary challenge: <strong>OOD Error</strong>. Historical datasets cover only a fraction of the total state manifold, known as the <strong>Behavior Manifold</strong>. The environment may contain a vast state space, but the data is merely a thin thread.</p> <p>The OOD problem in Offline RL is essentially a trajectory falling off the data manifold. In regions outside the manifold, the Value Function (Q-function) lacks a support set and often produces hallucinatory overestimations. Therefore, the core of modern RL algorithms lies in constraining the policy to adhere closely to the surface of the known manifold, preventing slippage into the geometric unknown.</p> <h2 id="iii-what-kind-of-manifold-does-general-intelligence-require"><strong>III. What Kind of Manifold Does General Intelligence Require?</strong></h2> <p>From the perspective of the Manifold Hypothesis, existing models (like GPT-4 or Stable Diffusion) mostly perform interpolation or pattern matching on <strong>known, fixed</strong> manifolds. AGI, however, requires models capable of navigating, expanding, and even creating manifolds.</p> <h3 id="1-a-globally-consistent-causal-world-model"><strong>1. A Globally Consistent Causal World Model</strong></h3> <p>AGI requires a <strong>unified, omni-modal Hyper-Manifold</strong>, which necessitates:</p> <ul> <li> <p>Constructing a <strong>low-level, modality-agnostic latent space</strong>. In this space, seeing an image of an “apple,” hearing the sound “Apple,” or perceiving Newton’s law of gravity all map to the <strong>essential geometric structure</strong> of the same physical entity.</p> </li> <li> <p>Incorporating not just correlations, but <strong>Time Arrows</strong> and <strong>Causal Graph</strong> structures. This implies paths on the manifold are <strong>directed</strong>. On the manifold, A→B might be a feasible trajectory, while B→A is prohibited by manifold boundaries (e.g., physical laws).</p> </li> </ul> <h3 id="2-core-agi-capability-reasoning-and-leaping-on-the-manifold"><strong>2. Core AGI Capability: Reasoning and Leaping on the Manifold</strong></h3> <p>Deep learning excels at intuition (smooth interpolation) but struggles with logic (extrapolation). Mathematical reasoning, for instance, requires precise multi-step deduction; slipping off the manifold at any step leads to error. AGI models must identify <strong>critical nodes</strong> on the manifold and establish <strong>Shortcuts</strong> between them via logical rules. Furthermore, they require imagination (e.g., counterfactual reasoning) to answer “What if?”. This demands the ability to artificially intervene on a variable and simulate a new trajectory on the manifold, even if such a trajectory never appeared in training data.</p> <h3 id="3-the-core-dilemma-sparse-observations-and-ill-posed-problems"><strong>3. The Core Dilemma: Sparse Observations and Ill-Posed Problems</strong></h3> <p>The fundamental barrier to AGI is data sparsity. Compared to the infinite possibilities of the real physical world, human-collected data is mathematically <strong>measure zero</strong>. This introduces a classic <strong>Ill-posed Problem</strong>:</p> <p>Imagine three black dots on a white paper, roughly forming an arc. The task is: “Draw the true curve where these three dots reside.” Without prior knowledge, the model faces <strong>infinite possibilities</strong>:</p> <ul> <li> <p><strong>Possibility A (Smooth):</strong> A smooth parabola.</p> </li> <li> <p><strong>Possibility B (Oscillating):</strong> A violently oscillating polyline passing through the dots at inflection points.</p> </li> <li> <p><strong>Possibility C (Complex):</strong> The outline of a sketch “cat,” where the dots are the ears and tail.</p> </li> <li> <p><strong>Possibility D (Discontinuous):</strong> Three independent, unrelated islands, not a continuous curve.</p> </li> </ul> <p>Without extra assumptions, there are infinite lines connecting these points. Relying solely on data points, <strong>the true manifold is unknowable</strong>.</p> <p>Humans solve this strategy via specific intuitions:</p> <ul> <li> <p><strong>Occam’s Razor:</strong> Preference for smoothness and simplicity. We assume the <strong>world is simple, continuous, and gradual</strong>. Unless evidence suggests violent oscillation, we default to smoothness. <strong>In manifold learning</strong>, this corresponds to regularization—forcing the model to find the simplest manifold.</p> </li> <li> <p><strong>Physical World Priors:</strong> We guess physical meaning through the points. If these points represent “a ball thrown in the air,” the likelihood of a parabola is maximized because gravity constrains the manifold shape via known physical equations (\(y=ax^2+bx+c\)). If they are “stock prices over three days,” a jagged line is probable, as the financial manifold is fractal and non-smooth.</p> </li> <li> <p><strong>Semantic Completion:</strong> If the dots suggest a triangle with a line below, humans infer a face. This is not curve fitting, but <strong>retrieving a manifold from memory</strong>. The human brain stores thousands of compressed “object manifolds.” Seeing the dots activates and projects the high-dimensional “face” manifold, which perfectly passes through the points.</p> </li> </ul> <p>Relying purely on data fitting, a model cannot determine the “true manifold” conforming to physical laws. Merely scaling data cannot fully cover the complex dynamics of high-dimensional space; extrapolation will inevitably fail. To reconstruct real-world manifolds under data scarcity, general AI cannot just be a “data fitter”—it must possess a <strong>meta-knowledge base</strong> akin to humans.</p> <h2 id="iv-the-inevitability-and-selection-of-inductive-bias"><strong>IV. The Inevitability and Selection of Inductive Bias</strong></h2> <p>In the discussion above, whether priors, semantic logic, or optimization logic like Occam’s Razor, the essence remains <strong>Inductive Bias</strong>. While we often aim to eliminate specific biases (e.g., in self-supervised learning), strictly speaking, <strong>a “bias-free” model does not exist</strong>.</p> <h3 id="1-why-cant-inductive-bias-be-eliminated"><strong>1. Why Can’t Inductive Bias Be Eliminated?</strong></h3> <p><strong>No Free Lunch Theorem:</strong> Without prior assumptions about data distribution, the expected performance of any learning algorithm is no better than random guessing. Without assuming the future resembles the past or adjacent points share similar values, a model cannot logically deduce any conclusion about the unknown from finite data. <strong>Inductive bias is not an algorithmic defect but a precondition for learning. Without bias, models face agnostic paralysis amidst sparse data.</strong> We cannot eliminate bias; we can only choose it. The question is not “if there is bias,” but “which bias has the strongest universality and lowest risk of falsification.” The success of GPT, in a sense, is that we selected or searched for the optimal objective (so far) for human language.</p> <h3 id="2-conjecture-what-biases-are-necessary"><strong>2. Conjecture: What Biases Are Necessary?</strong></h3> <p>Not all biases are beneficial; simple semantic biases are easily falsified by counterexamples. A plausible conjecture is that models leading to AGI require <strong>Meta-Priors</strong>—geometric and physical constraints regarding the universe’s underlying laws:</p> <ul> <li> <p><strong>Physical Symmetry:</strong> Hard-coding or soft-constraining translation, rotation, and time invariance into the architecture. This informs the model that however the manifold curls, it must obey conservation laws.</p> </li> <li> <p><strong>Causal Sparsity:</strong> Assuming the generative graph behind the manifold is sparse. This forces the model to decouple variables, avoiding spurious fully-connected correlations.</p> </li> <li> <p><strong>Algorithmic Minimalism:</strong> Based on Occam’s Razor, preferring the manifold structure with the lowest generative complexity (i.e., finding the shortest dynamic equation).</p> </li> </ul> <h2 id="v-dynamic-correction-from-static-priors-to-bayesian-manifold-evolution"><strong>V. Dynamic Correction: From Static Priors to Bayesian Manifold Evolution</strong></h2> <p>While meta-priors are robust, any preset bias may fail in specific environments. Thus, AGI models cannot rely on rigid priors but must possess the capability for <strong>dynamic correction of manifold structure</strong>.</p> <h3 id="1-predictive-coding-and-error-driven-learning"><strong>1. Predictive Coding and Error-Driven Learning</strong></h3> <p>Models should not be passive fitters but active predictors. Through self-supervised learning (e.g., predicting the next token or frame), the model constructs a current manifold hypothesis and deduces from it. When predictions drastically conflict with observations, this error signal should not merely adjust parameters but serve as the impetus for restructuring the manifold topology.</p> <h3 id="2-bayesian-manifolds-and-multi-hypothesis-maintenance"><strong>2. Bayesian Manifolds and Multi-Hypothesis Maintenance</strong></h3> <p>During data-sparse phases, the model should not collapse into a single manifold explanation but maintain a probability distribution of manifold families (<strong>Bayesian Manifold</strong>). As new data appears, <strong>Bayesian Updating</strong> adjusts the posterior probability of different manifold hypotheses.</p> <h3 id="3-active-intervention"><strong>3. Active Intervention</strong></h3> <p>To distinguish correlation manifolds from causal manifolds, the model must be capable of interacting with the environment—physically colliding with the world via intervention. Such interaction data is the sole touchstone capable of fundamentally falsifying incorrect manifold structures. Even for animals and humans, survival in the physical world reflects, to some extent, our level of intelligence.</p> <h2 id="epilogue"><strong>Epilogue</strong></h2> <p>Starting from the Manifold Hypothesis, what we need is not merely a massive statistical data fitter that overfits individual tasks based on human-defined inductive biases to achieve high benchmark scores. What truly matters may be a <strong>differentiable world simulator embedded with geometric meta-priors, capable of causal reasoning, and able to dynamically restructure itself via prediction errors</strong>. In this view, the essence of learning is not memorizing positions on a manifold, but capturing the differential equations that generate the manifold. The next stage of AI should be capable of surviving within dynamically changing manifolds; the ability required for such survival is likely the core of true intelligence.</p>]]></content><author><name></name></author><category term="English"/><category term="Tech-Blog"/><summary type="html"><![CDATA[Introduction: Geometric Order Amidst High-Dimensional Noise]]></summary></entry><entry><title type="html">流形假设(Manifold Hypothesis)下的思考·一</title><link href="https://edwardleelpz.github.io/%E4%B8%AD%E6%96%87/2025/11/25/manifold-hypothesis-1.html" rel="alternate" type="text/html" title="流形假设(Manifold Hypothesis)下的思考·一"/><published>2025-11-25T00:00:00+00:00</published><updated>2025-11-25T00:00:00+00:00</updated><id>https://edwardleelpz.github.io/%E4%B8%AD%E6%96%87/2025/11/25/manifold-hypothesis-1</id><content type="html" xml:base="https://edwardleelpz.github.io/%E4%B8%AD%E6%96%87/2025/11/25/manifold-hypothesis-1.html"><![CDATA[<h2 id="引言高维噪声中的几何秩序"><strong>引言：高维噪声中的几何秩序</strong></h2> <p>受到Kaiming大佬最近的的JiT启发，想聊聊在生成领域被广泛讨论的流形假设。类似的讨论虽然在生成领域已经屡见不鲜，但是其实际上是提供了一个理解现有深度学习架构的几何视角，可以潜在泛化到不同的任务和场景当中。</p> <p><strong>流形假设（Manifold Hypothesis）</strong> 是深度学习理论的基石之一。它试图解释神经网络能够在极高维的数据（如图像、文本、音频）上的出色表现。简单来说，流形假设认为：<strong>虽然现实世界的数据（如一张图片）在表面上由成千上万个维度 \(D\) （像素）组成，但它们实际上分布在一个内嵌入于高维空间中的低维（维度为 \(d\) 且 \(d\) 远小于 \(D\) ）流形上。</strong></p> <p>在数学拓扑学中，流形在局部近似欧几里得空间（比如平面或直线），但整体上可能有复杂结构的几何形状。为了更直观的理解，可以想象一张二维的纸（2D平面）：纸本身是二维的，由 \((u,v)\) 坐标描述。但若将其卷曲揉搓成一团，放在三维空间里中，对于观察者来说这个物体则存在于3D空间中，由 \((x,y,z)\) 坐标描述。但对于纸上的一只位于 \((u,v)\) 的蚂蚁来说，它仍然是一个二维世界。这里，这张卷曲的纸便对应了高维现实空间中数据所在的低维流形。</p> <p>流形假设在深度学习语境下包含以下几个关键推论：</p> <p><strong>1. 数据的自由度很低</strong></p> <p>数据的表观维度虽然庞大，但受现实条件约束，其真实自由度其实很少。以图像为例，一张人脸照片可能有几百万个像素，但这张图片的变化自由度其实很少，比如人脸的角度（上下左右）、光照的方向、面部表情（张嘴/闭嘴）等等。这些自由度构成了数据的<strong>固有维度</strong>。这意味着模型可能只需要几十个维度便可以精准刻画数据特征。</p> <p><strong>2. 神经网络的作用是展开流形</strong></p> <p>分类与回归任务的本质是处理流形的纠缠。在原始高维空间中，不同类别的流形可能像打结的绳子一样纠缠在一起，线性不可分。<strong>深度神经网络（尤其是深层结构）被认为是在对空间进行非线性的扭曲和拉伸</strong>。通过逐层的坐标系转换，卷曲的、纠缠的流形慢慢展开，直到其变得平坦且线性可分。</p> <p>沿用以上纸张的比喻，相当于有两张揉皱并缠在一起的纸（纠缠的流形）。神经网络的工作就是通过一系列精准的展开（层与层之间的非线性变换），小心翼翼地把它们抚平并分开，最后在中间画一条线（分类）。</p> <p>流形假设不仅仅是理论猜测，也在实际操作中得以验证：</p> <p><strong>1. 隐空间插值（Latent Space Interpolation）</strong></p> <p>如果在像素空间对两张人脸图片 A 和 B 进行线性插值（0.5A + 0.5B），则通常会得到一张重影的、不自然的图像，因为叠加后的数据离开了流形，到达了高维空间的空旷区域。</p> <p>但是，如果使用生成对抗网络（GAN）或变分自编码器（VAE），将图片映射到低维的隐空间后插值并解码回来，则会看到人脸 A 平滑、渐变地变成了人脸 B。这证明了数据确实形成了一个连续的低维流形，流形上的坐标迁移反映了数据特征的转变。</p> <p><strong>2. 对抗样本（Adversarial Examples）</strong></p> <p>对抗攻击通常是通过在图像上添加微小的扰动，含有流形法线方向的位移，使数据点脱离支撑集或穿越决策边界，导致模型分类错误。这反向说明了模型学习到的决策边界是紧贴着数据流形的，但在流形法向方向上极度脆弱。</p> <h2 id="一-深度学习范式的几何演进从拓扑解结到统一场论">一、 深度学习范式的几何演进：从拓扑解结到统一场论</h2> <p>当我们审视深度学习的不同范式时，会发现它们实际上是在以不同的方式操作和利用同一个流形结构。</p> <h3 id="1-判别任务classification--regression流形的解纠缠与分离"><strong>1. 判别任务（Classification / Regression）：流形的解纠缠与分离</strong></h3> <p>在原始像素空间中，不同类别的样本往往位于高度卷曲且相互纠缠的流形上，线性分类器无法将其分离。判别模型通过层级化的非线性变换，充当了拓扑学中的同胚映射算子。它不改变数据的拓扑性质，但通过拉伸和扭曲空间，忽略流形的内部度量结构，专注于最大化类间流形的距离。这就像将一团乱麻中的红纸和蓝纸解开，直至在高层特征空间中，它们变得平坦且线性可分。</p> <h3 id="2-生成任务generative-modeling流形的参数化与遍历"><strong>2. 生成任务（Generative Modeling）：流形的参数化与遍历</strong></h3> <p>生成模型关注的是流形本身的几何形状与概率密度。以扩散模型（Diffusion Models）为例，其去噪过程可被视为在高维能量景观中寻找流形的过程。模型学习了一个能够指示“距离流形有多远”的分数函数（Score Function/Gradient Field）。生成过程就像是一个随机落入高能高维空间噪点，沿梯度场轨迹收敛至低维流形表面的过程。</p> <h3 id="3-统一架构序列流形上的能量最小化"><strong>3. 统一架构：序列流形上的能量最小化</strong></h3> <p>当前最前沿的趋势是将判别与生成统一于同一架构，例如基于 Transformer 的 Next-Token Prediction。在流形视角下，这两者不再有本质区别，皆为序列流形上的轨迹延伸。<br/> 无论是输入“这张图是什么”（判别）还是“请画一只猫”（生成），模型都在给定起点的基础上，在流形表面规划一条使得能量函数最小化的路径。分类标签仅仅是流形上一种特殊的离散节点，而生成内容则是流形上的连续路径。这种视角消解了任务边界：大语言模型实际上是在构建一个联合语义流形，通过预测下一个 Token 来逼近流形的切空间方向。</p> <p>统一架构的优势主要在于<strong>流形约束互补（流形正则化）</strong>：纯判别模型只需要关注流形的<strong>边界</strong>而忽略流形<strong>内部的结构</strong>，导致对对抗样本脆弱；纯生成模型关注流形<strong>内部结构</strong>但对<strong>类间差异</strong>理解不足。而<strong>统一架构的优势</strong>在于强迫模型既要能画出流形（生成），又要能区分流形（判别），这迫使模型学习到的流形表示<strong>既精准（贴合数据分布）又鲁棒（边界清晰）</strong>。</p> <h3 id="4-多模态模型异构流形的同胚对齐"><strong>4. 多模态模型：异构流形的同胚对齐</strong></h3> <p>图像流形是连续的像素变化，文本流形是离散的符号组合。CLIP 或 GPT-4o 等多模态模型的核心挑战，在于寻找这两个异构几何体之间的共形映射。流形假设在此引入了一个核心概念：<strong>共享语义流形（Shared Semantic Manifold）</strong>。图像和文本仅仅是同一语义实体不同投影。多模态学习旨在构建一个共享的潜空间（Latent Space），使得“猫的图像”与“Cat”的词向量在该空间中重合，从而实现语义的统一。</p> <p>此外，凭借着统一架构的优势，简单的模态间语义对齐进一步发展成为跨模态理解。这种情况下，“Cat”这一文本token除了对应于猫这一<strong>语义锚点</strong>本身，也会更加贴近于诸如面部的胡须，身上的绒毛的low-level视觉表征。则进一步填满了不同模态流形之间的缺口，使共享语义流形更为平滑且完整。因此，多模态大模型在理解能力上往往优于单模态专家模型。</p> <h2 id="二-深度强化学习动态流形上的控制与规划"><strong>二、 深度强化学习：动态流形上的控制与规划</strong></h2> <p>当引入时间维度与决策机制，流形假设便从静态几何延伸至动态系统理论，这在深度强化学习（DRL）中体现得尤为深刻。与监督学习处理“静态”数据不同，DRL 处理的是动态的、交互式的数据流。</p> <h3 id="1-状态空间的物理降维"><strong>1. 状态空间的物理降维</strong></h3> <p>DRL 中的 Encoder 承担着<strong>将高维观测（如百万维的视频流）投影到低维物理状态流形</strong>的任务。这个流形的维度通常等同于系统的物理自由度（如关节角度、位置坐标）。有效的表征学习必须过滤掉光照、纹理等与动力学无关的“噪声维度”，仅保留决定系统演化的本质坐标。如果Encoder没有正确学到流形结构，它可能因为背景中一个无关像素的改变（在像素空间距离很远，但在物理流形上位置没变），就给出截然不同的动作预测。</p> <h3 id="2-动力学作为向量场"><strong>2. 动力学作为向量场</strong></h3> <p>物理定律在流形上定义了严格的<strong>向量场（Vector Field）或流（Flow）</strong>。Agent的策略Policy并非在真空中选择动作，而是在流形表面受到动力学约束的可行性管道（Feasible Tube）中规划测地线。状态不能在流形上随意跳跃，只能沿着动力学方程允许的方向移动。训练过程即是寻找一条通往高回报区域的最优曲线。</p> <h3 id="3-黎曼流形与自然梯度natural-gradient--trpo--ppo"><strong>3. 黎曼流形与自然梯度（Natural Gradient / TRPO / PPO）</strong></h3> <p>通常我们优化神经网络参数 \(θ\) 。但在 RL 中，我们真正关心的是 <strong>策略分布 \(πθ(a∣s)\)</strong> 的变化。但是在参数空间 \(θ\) 中走一小步（欧几里得距离），可能会导致策略分布发生剧烈变化，即导致 Policy Collapse，策略崩溃。参数空间并不是描述策略变化的正确几何空间。</p> <p>而当我们考虑策略分布时，其构成了一个<strong>统计流形</strong>。在这个流形上，测距尺度从欧几里得距离变为了 <strong>KL 散度</strong>。当使用TRPO时，TRPO 限制每次更新时，策略在<strong>流形上的移动距离</strong>（KL 散度）不能超过一个阈值。这就像在弯曲的地球表面行走，TRPO 确保模型沿着测地线走，而不是直接穿过地心。这解释了为什么 PPO/TRPO 比普通的 Policy Gradient 更稳定：它们尊重了策略空间的流形几何结构。</p> <h3 id="4-流形边界与分布外泛化ood"><strong>4. 流形边界与分布外泛化（OOD）</strong></h3> <p>当 Agent 不能与环境交互，只能从历史数据中学习时，流形假设解释了最大的难题：<strong>分布外误差（OOD Error）</strong>。历史数据集包含的轨迹只覆盖了整个状态流形的一小部分，即<strong>行为流形（Behavior Manifold）</strong>。整个环境可能包含巨大的状态空间，但数据只是一条细线。</p> <p>离线强化学习（Offline RL）中的 OOD 问题，本质上是策略轨迹掉出了数据流形。在流形外部的区域，价值函数Q-function由于缺乏支撑集，往往会产生高估的幻觉。因此，现代 RL 算法的核心在于通过约束策略，使其紧贴已知流形的表面，避免滑入未知的几何深渊。</p> <h2 id="三-通用智能所需要的流形是什么样的"><strong>三、 通用智能所需要的流形是什么样的</strong></h2> <p>基于流形假设的视角，现有的模型（如 GPT-4 或 Stable Diffusion）大多是在<strong>已知的、固定的</strong>流形上进行插值或模式匹配。而通用人工智能需要的模型，必须具备驾驭、扩展甚至创造流形的能力。</p> <h3 id="1-全局一致的因果世界模型"><strong>1. 全局一致的因果世界模型</strong></h3> <p>AGI 需要的是一个<strong>统一的、全模态的超流形（Hyper-Manifold），其</strong>需要：</p> <ul> <li>构建一个<strong>底层的、与模态无关的潜在空间</strong>。在这个空间里，无论是看到“苹果”的图像、听到“Apple”的声音、还是感受到牛顿的引力公式，它们都映射到同一个物理实体的<strong>本质几何结构</strong>上。</li> <li>不仅限于相关性，而是包含<strong>时间箭头</strong>和<strong>因果图</strong>结构。这意味着流形上的路径是<strong>有向的</strong>。在流形上，A→B 是可行的轨迹，但 B→A 可能是被物理定律等流形边界禁止的。</li> </ul> <h3 id="2-agi-的核心能力在流形上的推理与跳跃"><strong>2. AGI 的核心能力：在流形上的推理与跳跃</strong></h3> <p>深度学习擅长直觉（平滑插值），但不擅长逻辑（外推）。例如，数学推理往往需要多步精确推导，任何一步滑出流形都会导致错误。AGI 模型需要能够识别流形上的<strong>关键节点</strong>，并通过逻辑规则在这些节点之间建立<strong>Shortcuts</strong>。此外它还需具备想象力（例如反事实推理）要回答“如果……会怎样？”。这要求模型能够在流形上人为地通过干预改变某个变量，然后推演新的轨迹，即使这个轨迹从未在训练数据中出现过。</p> <h3 id="3-核心困境稀疏观测与不适定问题"><strong>3. 核心困境：稀疏观测与不适定问题</strong></h3> <p>迈向通用人工智能的根本障碍在于数据的稀疏性。相对于真实物理世界的无限可能性，人类所能收集的数据在数学上是<strong>测度为零（Measure Zero）</strong>的。这就引出了一个经典的<strong>不适定问题（Ill-posed Problem）</strong>：</p> <p>想象在一张白纸上画 3 个黑点，大致排成一条弧线。模型得到的任务是：“画出这就 3 个点所在的真实曲线。”如果没有任何先验知识，只看这三个点，模型会面临<strong>无穷多种可能性</strong>：</p> <ul> <li><strong>可能性 A（平滑）</strong>：一条平滑的抛物线。</li> <li><strong>可能性 B（震荡）</strong>：一条剧烈震荡的折线，恰好在拐点穿过了这三个点。</li> <li><strong>可能性 C（复杂）</strong>：一个简笔画的“猫”的轮廓，这三个点刚好是猫的耳朵和尾巴。</li> <li><strong>可能性 D（断裂）</strong>：根本不是一条连续的曲线，而是三个独立的、毫无关系的孤岛。</li> </ul> <p>在没有额外假设的情况下，连接这三个点的线有无数条。仅仅依靠数据点，<strong>真实的流形是不可知的</strong>，这就是所谓的不适定问题。</p> <p>人类解决这个问题的策略主要依靠以下几种直觉：</p> <ul> <li><strong>奥卡姆剃刀原则</strong>：偏好平滑与简单：我们通常认为<strong>世界是简单的、连续的、渐变的</strong>。如果没有证据表明这根线在疯狂抖动，则默认它是平滑的。<strong>在流形学习中</strong>，这对应了正则化，即强迫模型寻找最简单的那个流形。</li> <li><strong>物理世界的先验模板</strong>：我们往往透过点本身来猜测其物理意义。如果已知这三个点是“扔出去的球在空中的位置”，那么最大可能性应该是抛物线。因为重力定律用已知的物理方程（ \(y=ax^2+bx+c\) ）约束了流形的形状。如果已知这三个点是“一支股票连续三天的价格”，那么折线的可能性则非常大。因为在知识先验中，金融流形是分形的、不平滑的。</li> <li><strong>语义补全</strong>：在上述案例中，如果假设这三个点排成一个三角形，下面还有一条横线，那么很大概率上人类会判断这是一张脸。而这本质不是在拟合曲线，是在<strong>检索记忆中的流形</strong>。人类的大脑里存储了成千上万种“物体流形”的压缩包。当你看到这几个点时，“脸”这个高维流形被激活和投影，完美地通过了这几个点。</li> </ul> <p>单纯依赖数据拟合，模型无法确定哪一条才是符合真实物理法则的“真流形”。这意味着，仅靠扩大数据规模，永远无法通过插值完全覆盖高维空间的复杂动态，外推必然失败。通用的 AI 如果想在数据稀缺的情况下还原真实世界流形，它不能只做一个“数据拟合器”，它必须拥有像人类一样的<strong>元知识库</strong>。</p> <h2 id="四-归纳偏置的必然性与选择"><strong>四、 归纳偏置的必然性与选择</strong></h2> <p>在上述的讨论中，无论是先验模板还是语义逻辑，甚至是奥卡姆剃刀原则这中优化逻辑，其本质依然是<strong>归纳偏置（Inductive Bias）</strong>。虽然归纳偏置在很多时候都是局限于某一场景或模型，也是很多时候我们想要消除的核心（例如自监督学习），但是事实上<strong>并不存在所谓的“无偏见”模型</strong>。</p> <h3 id="1-为什么无法消除归纳偏置"><strong>1. 为什么无法消除归纳偏置？</strong></h3> <p>No Free Lunch：如果对数据分布没有任何先验假设，任何学习算法的期望性能都与随机猜测无异。也就是说，如果不做出某种假设，比如未来可能和过去相似或相邻的点可能有相似的值，模型就无法从有限的数据中通过逻辑推导出任何关于未知的结论。<strong>归纳偏置不是算法的缺陷，而是学习能够发生的先决条件。没有偏置，模型面对稀疏数据时将陷入不可知论的瘫痪</strong>。我们无法消除 Bias，我们只能选择 Bias。问题的关键不在于“是否有 Bias”，而在于“哪个 Bias 的普适性最强、被证伪的风险最低”。GPT的成功，某种意义上时我们选择或者搜寻到了对于人类语言来说最优（至少截止目前来看）的objective。</p> <h3 id="2-猜测什么样的偏置是必要的"><strong>2. 猜测：什么样的偏置是必要的？</strong></h3> <p>并非所有的偏置都是有益的,简单的语义偏置容易被反例证伪。一种简单的猜测是：通向 AGI 的模型需要的是元先验（Meta-Priors），即关于宇宙底层运行规律的几何与物理约束：</p> <ul> <li><strong>物理对称性：</strong> 将平移、旋转、时间不变性硬编码或软约束进模型架构。这相当于告诉模型，无论流形如何卷曲，它必须遵守守恒定律。</li> <li><strong>因果稀疏性：</strong> 假设流形背后的生成图是稀疏的。这强迫模型解耦变量，避免建立虚假的全连接相关性。</li> <li><strong>算法极简性：</strong> 依据奥卡姆剃刀原则，倾向于选择生成复杂度最低的流形结构（即寻找最短的动力学方程）。</li> </ul> <h2 id="五-动态修正从静态先验到贝叶斯流形演化"><strong>五、 动态修正：从静态先验到贝叶斯流形演化</strong></h2> <p>虽然元先验极其稳健，但任何预设的偏置都有可能在特定环境下失效。因此，AGI 模型不能依赖僵化的先验，而必须具备<strong>动态修正流形结构</strong>的能力。</p> <h3 id="1-预测编码与误差驱动"><strong>1. 预测编码与误差驱动</strong></h3> <p>模型不应只是被动拟合，而应成为主动的预测者。通过自监督学习（如预测下一个 Token 或下一帧），模型构建当前的流形假设并进行推演。当预测结果与观测数据发生剧烈冲突时，这个误差信号不应仅仅用来调整参数，更应成为重构流形拓扑的动力。</p> <h3 id="2-贝叶斯流形与多假设维持"><strong>2. 贝叶斯流形与多假设维持</strong></h3> <p>在数据稀疏阶段，模型不应坍缩到单一的流形解释上，而应维护一个流形族的概率分布（Bayesian Manifold）。当新数据出现时，通过贝叶斯更新（Bayesian Updating）调整不同流形假设的后验概率。</p> <h3 id="3-主动干预"><strong>3. 主动干预</strong></h3> <p>要区分相关性流形与因果流形，模型必须具备和所处环境交互的能力，即通过干预来物理碰撞世界。这种交互数据是唯一能从根本上证伪错误流形结构的试金石。甚至对于动物和人类来讲，在物理世界中存活的能力和时间一定程度上反映了我们的智能水平。</p> <h2 id="结语"><strong>结语</strong></h2> <p>从流形假设出发，我们所需要的不再是一个单纯的大数据统计拟合器，基于人类提出的各种归纳偏置来overfit个别任务，在benchmark上刷出多高的性能。真正重要的也许是一个<strong>内嵌几何元先验、具备因果推理能力、且能通过预测误差动态重构自身结构的可微分世界模拟器</strong>。在这个视角下，学习的本质不是记忆数据在流形上的位置，而是捕捉生成这个流形的微分方程。而下一个阶段的AI，应该可以在动态变化的流形中生存下来，这种生存本身需要的能力，可能才是最为核心的智能。</p>]]></content><author><name></name></author><category term="中文"/><category term="Tech-Blog"/><summary type="html"><![CDATA[引言：高维噪声中的几何秩序]]></summary></entry></feed>